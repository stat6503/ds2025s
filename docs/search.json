[
  {
    "objectID": "index.html#강의-안내",
    "href": "index.html#강의-안내",
    "title": "2025 창의융합과제연구(R&E 활동)",
    "section": "강의 안내",
    "text": "강의 안내\n\n일시 : 2025년 7월 21일(월)~24일(목) 8:30~17:30, 25일(금) 8:30~10:30\n장소 : 전북대학교 창조1관 202호 컴퓨터실습실\n문의 : stat6503@gmail.com, 010-2069-6824\n사전 설문조사"
  },
  {
    "objectID": "index.html#참고자료",
    "href": "index.html#참고자료",
    "title": "2025 창의융합과제연구(R&E 활동)",
    "section": "참고자료",
    "text": "참고자료\n\n개념잡는 데이터분석 with 머신러닝 / 장은실, 양숙희, 오경선 / 2023 / 배움터\nwebsite : 점프 투 파이썬"
  },
  {
    "objectID": "3_3_classification.html",
    "href": "3_3_classification.html",
    "title": "\n\n지도학습 : 분류\n",
    "section": "",
    "text": "지도학습 : 분류"
  },
  {
    "objectID": "3_3_classification.html#k-최근접-이웃",
    "href": "3_3_classification.html#k-최근접-이웃",
    "title": "\n\n지도학습 : 분류\n",
    "section": "9.1. K-최근접 이웃",
    "text": "9.1. K-최근접 이웃\n\n분류(classification)\n\n지도학습의 한 종류로, 정답(label)이 범주형 변수일 때 사용됨\n각 데이터가 속하는 집단(category) 간 관계를 학습함\n학습된 모델은 새로운 데이터가 속하는 집단을 예측할 수 있음\n\n\n\n\n혼동 행렬(confusion matrix)\n\n\n\n\n구분\n예측 Positive\n예측 Negative\n\n\n\n\n실제 Positive\nTrue Positive(TP)\nFalse Negative(FN)\n\n\n실제 Negative\nFalse Positive(FP)\nTrue Negative(TN)\n\n\n\n\n\n분류모델 평가지표 |지표|설명| |:——|:——————————| |정확도(accuracy)|전체 중에서 실제와 동일하게 예측한 비율, \\(\\frac{TP + TN}{TP + TN + FP + FN}\\)| |정밀도(precision)|모델이 양성이라고 예측한 것 중에서 실제로 양성인 비율, \\(\\frac{TP}{TP + FP}\\)| |재현율(recall, sensitivity)|실제 양성 중에서 모델이 양성이라고 예측한 비율, \\(\\frac{TP}{TP + FN}\\)| |특이도(specificity)|실제 음성 중에서 모델이 음성이라고 예측한 비율, \\(\\frac{TN}{TN + FP}\\)| |F1-score|정밀도와 재현율의 조화 평균|\n\n\n\nK-최근접 이웃(K-Nearest Neighbors; K-NN)\n\n새로운 데이터가 입력되었을 때, 가장 가까운 k개의 이웃 데이터를 기준으로 분류하는 통계 기법\n\n새로운 데이터와 가장 거리가 가까운 k개의 데이터를 찾음\n해당 k개의 데이터가 가장 많이 속한 클래스(class)로 새로운 데이터를 분류함(다수결 원리)\n\n일반적으로 k는 동점 상황을 피하기 위해 홀수로 설정함\n거리 계산에는 주로 유클리디안 거리(Euclidean distance)를 사용함\n\n\n\n\n예 : 천혜향과 레드향의 선호도 예측\n\nk=3일 때, 새로운 사람의 선호하는 맛(별 모양)과 가장 가까운 거리에 있는 3개의 데이터를 찾음\n이웃 중 레드향을 좋아하는 사람이 2명, 천혜향을 좋아하는 사람이 1명이므로, 새로운 사람은 레드향을 선호하는 것으로 분류함\n\n\n\n\n\n\nk 값\n\nK-NN 알고리즘은 탐색할 이웃의 개수(k)에 따라 분류 결과가 달라질 수 있음\n\nk가 너무 크면, 데이터의 세세한 패턴을 반영하지 못해 과소적합 발생\nk가 너무 작으면, 개별 데이터에 민감하게 반응하여 과대적합 발생\n\n일반적으로 최적의 k 값은 교차검증을 통해 모형 성능이 가장 좋은 k 값으로 결정함\n\n\n\n\n최적의 k 값 선택(하이퍼파라미터 튜닝; hyperparameter tunning)\n\n교차검증(cross-validation) 수행\n\n데이터를 여러 조각(fold)으로 나누고, 각 조각을 번갈아가며 검증 데이터(test data)로 사용\n각 반복에서 모델 평가지표(정확도, F1-score, 정밀도, 재현도 등)를 계산\n보통 각 반복에서 산출한 모델 평가지표의 평균 값을 모델 성능의 추정값으로 사용\n\n여러 이웃 수 k 값에 대해 교차검증을 반복 수행하여 각 k 값별로 모델 성능의 추정값을 계산\n모델 성능이 가장 좋은 k 값을 최적의 값으로 선택\n\n\n\n\n\n\n표준화 작업\n\nK-NN 알고리즘은 거리를 기반으로 하기 때문에, 데이터의 단위나 크기 차이가 크면 특정 특성(feature)이 크게 영향을 미쳐 엉뚱한 결과가 나올 수 있음\n따라서 모든 특성이 비슷한 스케일(scale)로 반영되도록 표준화 작업이 필수적임\n대표적인 표준화 방법은 다음과 같음\n\nz-점수 표준화 : 평균이 0, 표준편차가 1이 되도록 변환하는 방법, \\(x' = \\frac{x-\\mu}{\\sigma}\\)\n최대-최소 표준화 : 데이터의 0~1 범위로 변환하는 방법, \\(x' = \\frac{x-min(x)}{max(x)-min(x)}\\)"
  },
  {
    "objectID": "3_3_classification.html#실습-인기-영화-분류",
    "href": "3_3_classification.html#실습-인기-영화-분류",
    "title": "\n\n지도학습 : 분류\n",
    "section": "9.2. (실습) 인기 영화 분류",
    "text": "9.2. (실습) 인기 영화 분류\n\n[데이터] 캐글에서 제공하는 영화 데이터\n\n총 4,775개의 관측값과 27개의 변수로 구성됨\n[실습파일] chap11_movie_genre_final.csv\n\n\n\n\n## (1) 데이터 확인 및 전처리\n\n\n# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# 데이터 불러오기\ndf = pd.read_csv('./data/chap11_movie_genre_final.csv')\ndf.head(2)\n\n\n\n\n\n\n\n\nid\noriginal_title\ntarget\nvote_average\nAction\nAdventure\nFantasy\nScienceFiction\nCrime\nDrama\n...\nMystery\nHistory\nWar\nMusic\nDocumentary\nForeign\nTVMovie\ndirector\ncast\nkeywords\n\n\n\n\n0\n19995\nAvatar\n7\n7.2\n1\n1\n1\n1\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\nJames Cameron\nSamWorthington,SigourneyWeaver,StephenLang,Zoe...\n['culture clash', 'future', 'space war', 'spac...\n\n\n1\n285\nPirates of the Caribbean: At World's End\n7\n6.9\n1\n1\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\nGore Verbinski\nJohnnyDepp,KeiraKnightley,OrlandoBloom,Stellan...\n['ocean', 'drug abuse', 'exotic island', 'east...\n\n\n\n\n2 rows × 27 columns\n\n\n\n\n# 데이터 정보\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 4775 entries, 0 to 4774\nData columns (total 27 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   id              4775 non-null   int64  \n 1   original_title  4775 non-null   object \n 2   target          4775 non-null   int64  \n 3   vote_average    4775 non-null   float64\n 4   Action          4775 non-null   int64  \n 5   Adventure       4775 non-null   int64  \n 6   Fantasy         4775 non-null   int64  \n 7   ScienceFiction  4775 non-null   int64  \n 8   Crime           4775 non-null   int64  \n 9   Drama           4775 non-null   int64  \n 10  Thriller        4775 non-null   int64  \n 11  Animation       4775 non-null   int64  \n 12  Family          4775 non-null   int64  \n 13  Western         4775 non-null   int64  \n 14  Comedy          4775 non-null   int64  \n 15  Romance         4775 non-null   int64  \n 16  Horror          4775 non-null   int64  \n 17  Mystery         4775 non-null   int64  \n 18  History         4775 non-null   int64  \n 19  War             4775 non-null   int64  \n 20  Music           4775 non-null   int64  \n 21  Documentary     4775 non-null   int64  \n 22  Foreign         4775 non-null   int64  \n 23  TVMovie         4775 non-null   int64  \n 24  director        4745 non-null   object \n 25  cast            4732 non-null   object \n 26  keywords        4775 non-null   object \ndtypes: float64(1), int64(22), object(4)\nmemory usage: 1007.4+ KB\n\n\n\n# 데이터 전처리 : 결측값 확인\n# 영화 장르를 특성(feature)으로 사용할 예정이므로,\n# director, cast 변수에 존재하는 결측값은 별도로 처리하지 않음\ndf.isna().sum()\n\nid                 0\noriginal_title     0\ntarget             0\nvote_average       0\nAction             0\nAdventure          0\nFantasy            0\nScienceFiction     0\nCrime              0\nDrama              0\nThriller           0\nAnimation          0\nFamily             0\nWestern            0\nComedy             0\nRomance            0\nHorror             0\nMystery            0\nHistory            0\nWar                0\nMusic              0\nDocumentary        0\nForeign            0\nTVMovie            0\ndirector          30\ncast              43\nkeywords           0\ndtype: int64\n\n\n\n\n## (2) 데이터 탐색\n\n\n# target 변수에 따른 영화 수\nplt.figure(figsize=(5, 3))\nplt.title('Distribution of Target')\nsns.histplot(df['target'], bins=10, kde=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n# 영화 평균 평점 분포\nplt.figure(figsize=(5, 3))\nplt.title(\"Distribution of Average Movie Rating\")\nsns.histplot(df['vote_average'], bins=20, kde=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n# 데이터 집계 : 장르별 영화 수 (오름차순 정렬)\ngenre_count = df.loc[:, 'Action':'TVMovie'].sum()\ngenre_count.sort_values(inplace=True)\ngenre_count\n\nTVMovie              8\nForeign             33\nWestern             81\nDocumentary        110\nWar                143\nMusic              184\nHistory            191\nAnimation          232\nMystery            347\nFantasy            421\nFamily             512\nHorror             518\nScienceFiction     535\nCrime              691\nAdventure          786\nRomance            891\nAction            1140\nThriller          1270\nComedy            1714\nDrama             2281\ndtype: int64\n\n\n\n# 장르별 영화 수\n# 가장 많은 영화 장르는 드라마이고, 다음으로는 코미디, 스릴러, 액션 등의 순임\nplt.figure(figsize=(5, 5))\nplt.barh(genre_count.index, genre_count, color=sns.color_palette('hls',20))\nplt.show()\n\n\n\n\n\n\n\n\n\n# 상위 4개 장르에서 평균 평점 6.5 이상인 영화 수\n# 드라마 장르의 53.0%가 평균 평점이 6.5 이상으로 나타나므로,\n# 드라마 장르는 많이 제작되고 대중적 인기도 높다는 것을 알 수 있음\ntop_genres = ['Drama', 'Comedy', 'Thriller', 'Action']\nmin_avg_rating = 6.5\nfor genre in top_genres:\n    mask = (df[genre] == 1) & (df['vote_average']&gt;=min_avg_rating)\n    total = genre_count[genre]\n    above_count = len(df[mask])\n    percent = above_count/total*100\n    print(f'{genre} 장르 영화 {total}편 중에서 평균 평점 {min_avg_rating} 이상인 영화 수 : {above_count}편 ({percent:.1f}%)')\n\nDrama 장르 영화 2281편 중에서 평균 평점 6.5 이상인 영화 수 : 1208편 (53.0%)\nComedy 장르 영화 1714편 중에서 평균 평점 6.5 이상인 영화 수 : 521편 (30.4%)\nThriller 장르 영화 1270편 중에서 평균 평점 6.5 이상인 영화 수 : 415편 (32.7%)\nAction 장르 영화 1140편 중에서 평균 평점 6.5 이상인 영화 수 : 355편 (31.1%)\n\n\n\n\n## (3) K-NN을 이용한 분류\n\n\n# 훈련 데이터와 평가 데이터로 분할 (8:2 비율)\n# stratify=y 옵션 설정\n# → 분류 문제에서 각 클래스(calss)가 훈련 데이터와 평가 데이터에 비슷한 비율로 포함되도록 함\n#   클래스 불균형 문제를 완화하고 모델 성능을 안정적으로 평가하기 위함\nX = df[['Action', 'Adventure', 'Fantasy', 'ScienceFiction', 'Crime', 'Drama', 'Thriller',\n        'Animation', 'Family', 'Western', 'Comedy', 'Romance', 'Horror', 'Mystery',\n        'History', 'War', 'Music', 'Documentary', 'Foreign', 'TVMovie']]\ny = df['target']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n\n# 최적의 k 값 선택\n# cv : 교차검증 폴드(fold) 수 (기본값 5)\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\n\nk_range = range(1, 21, 2)\nk_scores = []\n\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X_train, y_train, cv=2, scoring='accuracy')\n    k_scores.append(scores.mean())\n    print(f'k={k}일 때 정확도 : {scores.mean():.3f}')\n\nk=1일 때 정확도 : 0.291\nk=3일 때 정확도 : 0.330\nk=5일 때 정확도 : 0.373\nk=7일 때 정확도 : 0.382\nk=9일 때 정확도 : 0.388\nk=11일 때 정확도 : 0.393\nk=13일 때 정확도 : 0.402\nk=15일 때 정확도 : 0.417\nk=17일 때 정확도 : 0.424\nk=19일 때 정확도 : 0.432\n\n\n\n# 모델 성능이 가장 좋은 k 값 선택\nbest_k = k_range[k_scores.index(max(k_scores))]\nprint(f\"최적의 k 값은 {best_k}이며, 평균 정확도는 {max(k_scores):.3f}\")\n\n최적의 k 값은 19이며, 평균 정확도는 0.432\n\n\n\n# K-NN 분류모델 생성 및 학습\nknn = KNeighborsClassifier(n_neighbors=best_k)\nknn.fit(X_train, y_train)\n\n# 분류모델 평가 : 정확도\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\ny_pred = knn.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n\nprint(f\"정확도 : {accuracy:.3f}\")\nprint(f\"정밀도 : {precision:.3f}\")\nprint(f\"재현율 : {recall:.3f}\")\n\n정확도 : 0.443\n정밀도 : 0.385\n재현율 : 0.443\n\n\n\n# Action, Thriller 장르일 때, target 예측\nnewdata = pd.DataFrame([[1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]], columns=X_train.columns)\ny_pred = knn.predict(newdata)\nprint(f'Action, Thriller 장르일 때, target 예측값 : {y_pred[0]:.0f}')\n\nAction, Thriller 장르일 때, target 예측값 : 7\n\n\n\n\n결과 및 시사점\n\n정확도는 43.8%로, 전체 영화 중 약 절반 이하만 정답 클래스를 올바르게 분류함\n정밀도는 37.8%로, 재현율은 43.8%로, 전체 클래스에 대한 평균적인 분류 성능이 낮은 편임\n세 지표가 모두 낮게 나타났으며, 이는 입력 데이터로 사용한 장르 정보만으로는 target을 효과적으로 구분하기 어려운 것으로 판단됨\n또한 target에서 클래스 불균형이 존재하여, 일부 클래스는 모델이 거의 예측하지 못했을 가능성도 있음\n따라서 모델 성능 개선을 위해 감독, 배우, 개봉 연도, 제작 국가 등의 추가적인 특성을 포함할 필요가 있음"
  },
  {
    "objectID": "3_3_classification.html#실습-농구선수-분류",
    "href": "3_3_classification.html#실습-농구선수-분류",
    "title": "\n\n지도학습 : 분류\n",
    "section": "9.3. (실습) 농구선수 분류",
    "text": "9.3. (실습) 농구선수 분류\n\n[데이터] 농구선수 데이터\n\n총 1,340개의 관측값과 6개의 변수로 구성됨\nTarget 변수는 선수의 경력이 5년 이상이면 1, 5년 미만이면 0을 나타냄\n[실습파일] chap11_basketball_final.csv\n\n\n\n\n선수의 기량을 보고 5년 이상 경력을 가졌는지 예측할 수 있을까?\n\n\n\n## (1) 데이터 확인 및 전처리\n\n\n# 데이터 불러오기\ndf = pd.read_csv('./data/chap11_basketball_final.csv')\ndf.head()\n\n\n\n\n\n\n\n\nRebounds\nAssists\nSteals\nBlocks\nTurnovers\nTarget\n\n\n\n\n0\n4.1\n1.9\n0.4\n0.4\n1.3\n0\n\n\n1\n2.4\n3.7\n1.1\n0.5\n1.6\n0\n\n\n2\n2.2\n1.0\n0.5\n0.3\n1.0\n0\n\n\n3\n1.9\n0.8\n0.6\n0.1\n1.0\n1\n\n\n4\n2.5\n0.3\n0.3\n0.4\n0.8\n1\n\n\n\n\n\n\n\n\n# 데이터 정보\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1340 entries, 0 to 1339\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Rebounds   1340 non-null   float64\n 1   Assists    1340 non-null   float64\n 2   Steals     1340 non-null   float64\n 3   Blocks     1340 non-null   float64\n 4   Turnovers  1340 non-null   float64\n 5   Target     1340 non-null   int64  \ndtypes: float64(5), int64(1)\nmemory usage: 62.9 KB\n\n\n\n# 데이터 전처리 : 결측값 확인\ndf.isna().sum()\n\nRebounds     0\nAssists      0\nSteals       0\nBlocks       0\nTurnovers    0\nTarget       0\ndtype: int64\n\n\n\n\n## (2) 데이터 탐색\n\n\n# 5년 이상 경력 여부에 따른 선수 분포\nplt.figure(figsize=(5, 3))\nplt.title('Distribution of Experience')\nsns.countplot(x=df['Target'])\nplt.xlabel('')\nplt.xticks([0, 1], ['under 5 years', '5 years or more'])\nplt.show()\n\n\n\n\n\n\n\n\n\n# 5년 이상 경력 여부에 따른 평균 농구 기술\ndf_mean = df.groupby('Target').mean()\n\n\n# 5년 이상 경력 여부에 따른 평균 농구 기술 비교\n# 경기 기여도가 높은 기술(리바운드, 어시스트, 스틸, 블록)은 경력이 5년 이상인 선수가 더 뛰었났음\n# 하지만 턴오버 횟수도 경력이 5년 이상인 선수가 더 많은 것으로 나타남\nplt.figure(figsize=(8, 3))\nsns.heatmap(df_mean, annot=True, cmap='Oranges', square=True)\nplt.ylabel('Experience')\nplt.yticks([0.5, 1.5], ['under \\n5 years', '5 years\\n or more'], rotation=0)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n## (3) K-NN을 이용한 분류\n\n\n# 훈련 데이터와 평가 데이터로 분할 (8:2 비율)\nX = df[['Rebounds','Assists','Steals','Blocks','Turnovers']]\ny = df['Target']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n# 최적의 k 값 선택\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\n\nk_range = range(1, 21, 2)\nk_scores = []\n\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X_train, y_train, cv=2, scoring='accuracy')\n    k_scores.append(scores.mean())\n    print(f'k={k}일 때 정확도 : {scores.mean():.3f}')\n\nk=1일 때 정확도 : 0.576\nk=3일 때 정확도 : 0.621\nk=5일 때 정확도 : 0.617\nk=7일 때 정확도 : 0.622\nk=9일 때 정확도 : 0.635\nk=11일 때 정확도 : 0.634\nk=13일 때 정확도 : 0.652\nk=15일 때 정확도 : 0.646\nk=17일 때 정확도 : 0.644\nk=19일 때 정확도 : 0.645\n\n\n\n# 모델 성능이 가장 좋은 k 값 선택\nbest_k = k_range[k_scores.index(max(k_scores))]\nprint(f\"최적의 k 값은 {best_k}이며, 평균 정확도는 {max(k_scores):.3f}\")\n\n최적의 k 값은 13이며, 평균 정확도는 0.652\n\n\n\n# K-NN 분류모델 생성 및 학습\nknn = KNeighborsClassifier(n_neighbors=best_k)\nknn.fit(X_train, y_train)\n\n# 분류모델 평가 : 정확도\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\ny_pred = knn.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\n\nprint(f\"정확도 : {accuracy:.3f}\")\nprint(f\"정밀도 : {precision:.3f}\")\nprint(f\"재현율 : {recall:.3f}\")\n\n정확도 : 0.664\n정밀도 : 0.703\n재현율 : 0.811\n\n\n\n# Rebounds 3회, Assists 3회, Steals 2회, Blocks 2회, Turnovers 4회일 때,\n# 5년 이상 경력 여부 예측\nnewdata = pd.DataFrame([[3, 3, 2, 2, 4]], columns=X_train.columns)\ny_pred = knn.predict(newdata)\ny_pred = pd.Series(y_pred).map({0: 'under 5 years', 1: '5 years and over'})\nprint(f'Rebounds 3회, Assists 3회, Steals 2회, Blocks 2회, Turnovers 4회일 때, 예측값 : {y_pred[0]}')\n\nRebounds 3회, Assists 3회, Steals 2회, Blocks 2회, Turnovers 4회일 때, 예측값 : 5 years and over\n\n\n\n\n결과 및 시사점\n\n정확도는 66.4%로, 3명의 중 2명은 경력을 올바르게 분류함\n정밀도는 70.3%로, 모델이 경력 5년 이상이라고 예측한 선수 중 약 70%가 실제로 경력이 많았음\n재현율은 81.1%로, 실제로 경력 5년 이상인 선수 대부분을 모델이 정확히 분류함\n모델 성능은 전반적으로 양호하며, 특히 높은 재현율을 통해 경력이 많은 선수를 잘 포착하는 경향을 보임\n다만 정확도와 정밀도는 개선 여지가 있으며, 이를 위해 득점, 평균 출전 시간, 포지션 등의 추가적인 특성을 고려해볼 수 있음"
  },
  {
    "objectID": "3_1_machine_learning.html",
    "href": "3_1_machine_learning.html",
    "title": "\n\n머신러닝\n",
    "section": "",
    "text": "머신러닝"
  },
  {
    "objectID": "3_1_machine_learning.html#인공지능",
    "href": "3_1_machine_learning.html#인공지능",
    "title": "\n\n머신러닝\n",
    "section": "7.1. 인공지능",
    "text": "7.1. 인공지능\n\n인공지능(AI; Artificial Intelligence)\n\n컴퓨터가 인간처럼 인식, 사고, 학습, 문제 해결 등의 지능적인 작업을 수행하도록 만드는 기술\nAI는 주어진 데이터를 기반으로 학습하고 판단하기 때문에, 어떤 데이터를 학습시키느냐에 따라 결과가 크게 달라짐\n\n편향된 데이터나 잘못된 정보로 학습된 AI는 부정확하거나 차별적인 결과를 내릴 수 있음"
  },
  {
    "objectID": "3_1_machine_learning.html#머신러닝-알고리즘",
    "href": "3_1_machine_learning.html#머신러닝-알고리즘",
    "title": "\n\n머신러닝\n",
    "section": "7.2. 머신러닝 알고리즘",
    "text": "7.2. 머신러닝 알고리즘\n\n머신러닝(machine learning)\n\n컴퓨터가 데이터를 이용하여 스스로 학습하고, 문제 해결에 적합한 알고리즘이나 패턴을 찾아내는 기술\n학습한 내용을 활용하여 새로운 데이터에 대해 예측하고, 의사결정을 내릴 수 있음\n\n\n\n\n특성(feature)\n\n머신러닝 모델이 입력받는 데이터의 개별 속성(변수)으로, 학습에 사용하는 정보의 단위\n모델의 성능은 입력되는 특성(feature)의 품질에 크게 영향을 받으므로, 이를 적절히 가공하고 정제하는 전처리 과정은 매우 중요함\n\n\n\n\n7.2.1. 학습 방식에 따른 분류\n\n지도학습(supervised learning)\n\n입력 데이터와 해당 데이터에 대한 정답(label)을 함께 사용하여 모델을 학습하는 방법\n입력과 정답 데이터 간 관계를 학습하고, 새로운 입력 데이터에 대한 결과를 예측하거나 분류함\n대표적인 알고리즘으로는 선형 회귀, 로지스틱 회귀, 의사결정나무, 랜덤 포레스트, 서포트 벡터 머신(SVM), K-NN 등이 있음\n\n\n\n\n비지도학습(unsupervised learning)\n\n정답(label) 없이 입력 데이터만을 사용하여 모델을 학습하는 방법\n데이터 내에 숨겨진 구조나 패턴을 발견하거나, 군집화(clustering)하는데 사용함\n대표적인 알고리즘으로는 K-Means clustering, DBSCAN, PCA 등이 있음\n\n\n\n\n강화학습(reinforcement learning)\n\n에이전트가 환경과 상호작용하여 보상은 최대화하고, 패널티는 최소화하는 방향으로 학습하는 방법\n시행착오를 통해 최상의 행동 방침을 학습하며, 주로 게임, 로봇 제어 등 시뮬레이션에서 사용됨\n대표적인 알고리즘으로는 Q-러닝, 딥 Q-네트워크(DQN) 등이 있음\n\n\n\n  \n\n\n\n7.2.2. 과소적합과 과대적합\n\n과소적합(underfitting)\n\n모델이 학습 데이터를 제대로 이해하지 못해 성능이 낮은 상태\n주로 다음과 같은 경우에 발생함\n\n모델 복잡도가 너무 낮은 경우 (예: 복잡한 문제에 지나치게 단순한 모델에 적용)\n중요한 피쳐(feature)가 부족한 경우\n학습이 충분히 이루어지지 않은 경우\n\n\n\n\n\n과대적합(overfitting; 과적합)\n\n모델이 학습 데이터에만 과도하게 최적화되어, 새로운 데이터에서 성능이 떨어지는 상태\n주로 다음과 같은 경우에 발생함\n\n모델 복잡도가 너무 높은 경우\n학습 데이터가 부족한 경우\n정규화가 부족하여 일반화 성능이 낮은 경우\n\n\n\n\n\n\n\n\n7.2.3. 데이터 분할\n\n지도학습에서는 모델의 과적합을 방지하고 성능을 객관적으로 평가하기 위해 데이터를 여러 세트로 분할함\n\n학습 데이터(training data) : 모델이 패턴과 규칙을 학습하는 데 사용\n검증 데이터(validation data)(선택) : 학습 과정에서 하이퍼파라미터 튜닝이나 과대적합 여부 확인에 사용\n평가 데이터(test data) : 학습에 포함되지 않은 데이터로, 모델의 예측 결과와 실제 정답(label)을 비교하여 모델의 성능을 평가함\n\n일반적으로 데이터는 학습:검증:평가를 6:2:2 비율로 나눔"
  },
  {
    "objectID": "2_3_matplotlib.html",
    "href": "2_3_matplotlib.html",
    "title": "\n\nMatplotlib\n",
    "section": "",
    "text": "Matplotlib"
  },
  {
    "objectID": "2_3_matplotlib.html#데이터-시각화",
    "href": "2_3_matplotlib.html#데이터-시각화",
    "title": "\n\nMatplotlib\n",
    "section": "5.1. 데이터 시각화",
    "text": "5.1. 데이터 시각화\n\n데이터 시각화(data visualization)\n\n데이터 분석 결과를 쉽게 이해할 수 있도록 표현하고 전달되는 과정\n복잡한 정보를 한 눈에 파악하고, 숨겨진 패턴이나 관계를 드러냄\n탐색적 자료 분석(EDA), 결과 해석, 의사결정 등에 폭넓게 활용\n\n\n\n\n데이터 시각화 단계\n\n시각화 라이브러리 불러오기\nx축, y축에 표시할 데이터 정하기\nplot() 함수에 데이터 입력하기\n그래프 보여주기"
  },
  {
    "objectID": "2_3_matplotlib.html#시각화-옵션",
    "href": "2_3_matplotlib.html#시각화-옵션",
    "title": "\n\nMatplotlib\n",
    "section": "5.2. 시각화 옵션",
    "text": "5.2. 시각화 옵션\n\nMatplotlib\n\n넘파이 배열을 기반으로 개발된 다중 플랫폼 데이터 시각화 라이브러리\n다양한 운영체제와 그래픽 백엔드에서 안정적으로 작동함\n일반적으로 Pandas의 데이터프레임과 함께 자주 사용됨\n\n\n\n\n# Matplotlib 라이브러리 설치\n#!pip install matplotlib\n\n\n# Matplotlib 라이브러리의 pylot 모듈 불러오기\nimport matplotlib.pyplot as plt\n\n\nimport numpy as np\nimport pandas as pd\n\n\n# 시각화 옵션1 : 제목\nxdata = [3, 5, 7, 9]\nydata = [2, 4, 6, 8]\n\nplt.figure(figsize=(5, 3))\nplt.title('Line Graph')\nplt.plot(xdata, ydata)\nplt.show()\n\n\n\n\n\n\n\n\n\n# 시각화 옵션2 : 범례\n# plot()의 label 속성에 범례에 표시할 문자열을 작성\ndata1 = [1, 3, 5, 7]\ndata2 = [9, 7, 5, 3]\n\nplt.figure(figsize=(5, 3))\nplt.title('Legend Properties')\nplt.plot(data1, label='Salary')\nplt.plot(data2, label='Prices')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# 시각화 옵션3 : 색상\n# plot()의 color 속성에 색상 설정\nxdata = [3, 5, 7, 9]\nydata = [1, 3, 5, 7]\n\nplt.figure(figsize=(5, 3))\nplt.title('Color Properties')\nplt.plot(xdata, ydata, color='green')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 시각화 옵션4 : x축 및 y축 이름\nxdata = [3, 5, 7, 9]\nydata = [1, 3, 5, 7]\n\nplt.figure(figsize=(5, 3))\nplt.title('Axis name Properties')\nplt.plot(xdata, ydata)\nplt.xlabel('X value')\nplt.ylabel('Y value')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 시각화 옵션5 : 그래프 선 모양\n# plot()의 linestyle 속성에 선 모양을 '-', '--', '-.', ':' 등으로 설정\ndata1 = [1, 3, 5, 7]\ndata2 = [9, 7, 5, 3]\n\nplt.figure(figsize=(5, 3))\nplt.title('Line shape Properties')\nplt.plot(data1, color='b', linestyle='--', label='dashed')\nplt.plot(data2, 'r:', label='dotted')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# 시각화 옵션6 : 그림 범위 지정\nxdata = [15, 25, 35, 45]\nydata = [2, 4, 6, 8]\n\nplt.figure(figsize=(5, 3))\nplt.title('X, Y range Properties')\nplt.plot(xdata, ydata, 'b--o', markersize=7)\nplt.xlim(10, 50)\nplt.ylim(0, 10)\nplt.show()\n\n\n\n\n\n\n\n\n\n# 시각화 옵션7 : 내장 시각화 옵션\n# Pandas 라이브러리의 plot() 메소드를 이용하여 그래프를 그릴 수 있음\nmy_score = [[60, 90, 95], [65, 85, 90], [80, 75, 100],\n            [95, 90, 85], [85, 80, 65]]\nsubject = ['1st', '2nd', '3rd']\ndf = pd.DataFrame(my_score, columns=subject)\n\n# 선 그래프\ndf.plot(kind='line', figsize=(5, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\n# 상자수염 그래프\ndf.plot(kind='box', figsize=(5, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\n# SciPy 라이브러리 설치\n#!pip install scipy\n\n\n# 커널 밀도 그래프\ndf.plot(kind='kde', figsize=(5, 3))\nplt.show()"
  },
  {
    "objectID": "2_3_matplotlib.html#선-그래프",
    "href": "2_3_matplotlib.html#선-그래프",
    "title": "\n\nMatplotlib\n",
    "section": "5.3. 선 그래프",
    "text": "5.3. 선 그래프\n\n일반적으로 시간에 따라 연속적으로 변화하는 데이터를 시각화할 때 사용함\n\nx축에는 시간, y축에는 수치형 변수를 지정함\n시간의 흐름에 따라 데이터의 값은 증가/감소하는가?\n계절에 따른 특정 패턴이 존재하는가? 눈에 띄는 변화 시점이 있는가?\n\n\n\n\n[데이터] 에어코리아에서 제공하는 2015-2020년 연도별, 시도별, 미세먼지 등급별 일수\n\n미세먼지 등급 : 0-30(좋음), 31-80(보통), 81-150(나쁨), 151 이상(매우 나쁨)\n[실습파일] 04_data1.csv\n\n\n\n\n# 데이터 불러오기 : area' 변수를 행 인덱스로 지정\ndata = pd.read_csv('./data/04_data1.csv', index_col='area')\ndata.head()\n\n\n\n\n\n\n\n\n2015_good\n2016_good\n2017_good\n2018_good\n2019_good\n2020_good\n2015_common\n2016_common\n2017_common\n2018_common\n...\n2017_bad\n2018_bad\n2019_bad\n2020_bad\n2015_verybad\n2016_verybad\n2017_verybad\n2018_verybad\n2019_verybad\n2020_verybad\n\n\narea\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNationwide\n72.0\n54\n84\n135\n117\n171\n267.0\n297\n265\n209\n...\n14\n21\n16\n0\n1.0\n2\n2\n0\n1\n0\n\n\nMetropolitan\n72.0\n45\n77\n126\n109\n150\n259.0\n290\n260\n217\n...\n26\n22\n27\n4\n4.0\n2\n2\n0\n3\n0\n\n\nSeoul\n97.0\n65\n113\n140\n139\n168\n243.0\n277\n230\n204\n...\n20\n21\n25\n5\n4.0\n1\n2\n0\n3\n0\n\n\nBusan\n102.0\n89\n86\n136\n163\n208\n242.0\n259\n269\n212\n...\n10\n16\n9\n2\n1.0\n2\n0\n1\n0\n0\n\n\nDaegu\n90.0\n103\n111\n155\n148\n176\n248.0\n246\n244\n196\n...\n10\n13\n17\n4\n1.0\n1\n0\n1\n0\n0\n\n\n\n\n5 rows × 24 columns\n\n\n\n\n# '2015-2020년 미세먼지 좋음' 일수만 가져오기\ndata_good = data.copy()\ndata_good = data_good.loc[:, '2015_good':'2020_good']\ndata_good\n\n\n\n\n\n\n\n\n2015_good\n2016_good\n2017_good\n2018_good\n2019_good\n2020_good\n\n\narea\n\n\n\n\n\n\n\n\n\n\nNationwide\n72.0\n54\n84\n135\n117\n171\n\n\nMetropolitan\n72.0\n45\n77\n126\n109\n150\n\n\nSeoul\n97.0\n65\n113\n140\n139\n168\n\n\nBusan\n102.0\n89\n86\n136\n163\n208\n\n\nDaegu\n90.0\n103\n111\n155\n148\n176\n\n\nIncheon\n67.0\n49\n78\n140\n115\n182\n\n\nGwangju\n122.0\n151\n134\n149\n117\n210\n\n\nDaejeon\n111.0\n92\n83\n121\n143\n182\n\n\nUlsan\n101.0\n101\n104\n162\n173\n206\n\n\nSejong\nNaN\n65\n69\n130\n127\n165\n\n\nGyeonggi\n65.0\n45\n59\n123\n97\n137\n\n\nGangwon\n77.0\n65\n108\n150\n159\n219\n\n\nChungbuk\n90.0\n99\n106\n117\n113\n164\n\n\nChungnam\n94.0\n65\n74\n144\n96\n145\n\n\nJeonbuk\n86.0\n58\n69\n121\n108\n171\n\n\nJeonnam\n142.0\n166\n160\n191\n193\n247\n\n\nGyeongbuk\n101.0\n123\n124\n129\n142\n212\n\n\nGyeongnam\n76.0\n75\n93\n136\n136\n220\n\n\nJeju\n84.0\n138\n166\n202\n176\n220\n\n\n\n\n\n\n\n\n# 행렬 전환(transpose)\n# 인덱스는 열 이름이 되고, 열 이름은 인덱스가 됨\ndata_good = data_good.T\ndata_good\n\n\n\n\n\n\n\narea\nNationwide\nMetropolitan\nSeoul\nBusan\nDaegu\nIncheon\nGwangju\nDaejeon\nUlsan\nSejong\nGyeonggi\nGangwon\nChungbuk\nChungnam\nJeonbuk\nJeonnam\nGyeongbuk\nGyeongnam\nJeju\n\n\n\n\n2015_good\n72.0\n72.0\n97.0\n102.0\n90.0\n67.0\n122.0\n111.0\n101.0\nNaN\n65.0\n77.0\n90.0\n94.0\n86.0\n142.0\n101.0\n76.0\n84.0\n\n\n2016_good\n54.0\n45.0\n65.0\n89.0\n103.0\n49.0\n151.0\n92.0\n101.0\n65.0\n45.0\n65.0\n99.0\n65.0\n58.0\n166.0\n123.0\n75.0\n138.0\n\n\n2017_good\n84.0\n77.0\n113.0\n86.0\n111.0\n78.0\n134.0\n83.0\n104.0\n69.0\n59.0\n108.0\n106.0\n74.0\n69.0\n160.0\n124.0\n93.0\n166.0\n\n\n2018_good\n135.0\n126.0\n140.0\n136.0\n155.0\n140.0\n149.0\n121.0\n162.0\n130.0\n123.0\n150.0\n117.0\n144.0\n121.0\n191.0\n129.0\n136.0\n202.0\n\n\n2019_good\n117.0\n109.0\n139.0\n163.0\n148.0\n115.0\n117.0\n143.0\n173.0\n127.0\n97.0\n159.0\n113.0\n96.0\n108.0\n193.0\n142.0\n136.0\n176.0\n\n\n2020_good\n171.0\n150.0\n168.0\n208.0\n176.0\n182.0\n210.0\n182.0\n206.0\n165.0\n137.0\n219.0\n164.0\n145.0\n171.0\n247.0\n212.0\n220.0\n220.0\n\n\n\n\n\n\n\n\n# 열 이름 상단의 이름(label) 삭제\ndata_good.columns.name = ''\n\n# 인덱스를 연도(2015-2020)로 수정\ndata_good.index = range(2015, 2021)\ndata_good\n\n\n\n\n\n\n\n\nNationwide\nMetropolitan\nSeoul\nBusan\nDaegu\nIncheon\nGwangju\nDaejeon\nUlsan\nSejong\nGyeonggi\nGangwon\nChungbuk\nChungnam\nJeonbuk\nJeonnam\nGyeongbuk\nGyeongnam\nJeju\n\n\n\n\n2015\n72.0\n72.0\n97.0\n102.0\n90.0\n67.0\n122.0\n111.0\n101.0\nNaN\n65.0\n77.0\n90.0\n94.0\n86.0\n142.0\n101.0\n76.0\n84.0\n\n\n2016\n54.0\n45.0\n65.0\n89.0\n103.0\n49.0\n151.0\n92.0\n101.0\n65.0\n45.0\n65.0\n99.0\n65.0\n58.0\n166.0\n123.0\n75.0\n138.0\n\n\n2017\n84.0\n77.0\n113.0\n86.0\n111.0\n78.0\n134.0\n83.0\n104.0\n69.0\n59.0\n108.0\n106.0\n74.0\n69.0\n160.0\n124.0\n93.0\n166.0\n\n\n2018\n135.0\n126.0\n140.0\n136.0\n155.0\n140.0\n149.0\n121.0\n162.0\n130.0\n123.0\n150.0\n117.0\n144.0\n121.0\n191.0\n129.0\n136.0\n202.0\n\n\n2019\n117.0\n109.0\n139.0\n163.0\n148.0\n115.0\n117.0\n143.0\n173.0\n127.0\n97.0\n159.0\n113.0\n96.0\n108.0\n193.0\n142.0\n136.0\n176.0\n\n\n2020\n171.0\n150.0\n168.0\n208.0\n176.0\n182.0\n210.0\n182.0\n206.0\n165.0\n137.0\n219.0\n164.0\n145.0\n171.0\n247.0\n212.0\n220.0\n220.0\n\n\n\n\n\n\n\n\n# 선 그래프1 : 2015-2020 전국 미세먼지(PM10) 좋음 일수 변화 추이\nplt.figure(figsize=(8, 3))\nplt.title('2015-2020 Nationwide Fine Dust(PM10) - Good Days')\nplt.plot(data_good['Nationwide'], color='b', marker='o')\nplt.xlabel('Year')\nplt.ylabel('Count')\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n# 선 그래프2 : 2015-2020 전국, 수도권, 전북 미세먼지(PM10) 좋음 일수 변화 추이\nplt.figure(figsize=(8, 3))\nplt.title('2015-2020 Fine Dust(PM10) - Good Days By Area')\n\nfor area in ['Nationwide', 'Metropolitan', 'Jeonbuk']:\n    plt.plot(data_good[area], marker='o', label=area)\n\nplt.xlabel('Year')\nplt.ylabel('Count')\nplt.legend()\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "2_3_matplotlib.html#막대-그래프",
    "href": "2_3_matplotlib.html#막대-그래프",
    "title": "\n\nMatplotlib\n",
    "section": "5.4. 막대 그래프",
    "text": "5.4. 막대 그래프\n\n일반적으로 집단 간 비교나 범주형 변수를 시각화할 때 사용함\n가독성 측면에서 항목의 개수가 적으면 세로 막대, 많으면 가로 막대가 유리함\n\n\n\n# 전국, 수도권, 전북의 '2015년 미세먼지 매우 나쁨' 일수만 가져오기\ndata2015_verybad = data.copy()\ndata2015_verybad = data2015_verybad.loc[['Nationwide', 'Metropolitan', 'Jeonbuk'], '2015_verybad']\ndata2015_verybad\n\narea\nNationwide      1.0\nMetropolitan    4.0\nJeonbuk         3.0\nName: 2015_verybad, dtype: float64\n\n\n\n# 막대 그래프1 : 2015년 전국, 수도권, 전북 미세먼지(PM10) 매우 나쁨 일수 비교\nplt.figure(figsize=(5, 3))\nplt.title('2015 Fine Dust(PM10) - Very Bad Days By Area')\nplt.bar(data2015_verybad.index, data2015_verybad, color='c')\nplt.xlabel('Area')\nplt.ylabel('Count')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 전라권의 '2015-2020년 미세먼지 좋음' 일수만 가져오기\ndata6 = data.copy()\ndata6 = data6.loc[['Jeonbuk', 'Jeonnam', 'Gwangju'], '2015_good':'2020_good']\ndata6\n\n\n\n\n\n\n\n\n2015_good\n2016_good\n2017_good\n2018_good\n2019_good\n2020_good\n\n\narea\n\n\n\n\n\n\n\n\n\n\nJeonbuk\n86.0\n58\n69\n121\n108\n171\n\n\nJeonnam\n142.0\n166\n160\n191\n193\n247\n\n\nGwangju\n122.0\n151\n134\n149\n117\n210\n\n\n\n\n\n\n\n\n# 막대 그래프2 : 2015-2020 전라권 미세먼지(PM10) 좋음 일수 비교\nplt.figure(figsize=(8, 3))\nplt.title('2015-2020 Fine Dust(PM10) - Good Days By Jeolla Region')\n\nindex = np.arange(3)\nfor year in data6.columns:\n    plt.bar(index, data6[year], width=0.15, label=year.split(\"_\")[0])\n    index = index + 0.15\n\nplt.xlabel('Area')\nplt.ylabel('Count')\nplt.xticks(index-0.53, data6.index)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# 17개 시도의 '2020년 미세먼지 나쁨' 일수만 가져오기\ndata2020_bad = data.copy()\ndata2020_bad = data2020_bad.loc['Seoul':, '2020_bad']\ndata2020_bad\n\narea\nSeoul        5\nBusan        2\nDaegu        4\nIncheon      2\nGwangju      0\nDaejeon      1\nUlsan        2\nSejong       4\nGyeonggi     6\nGangwon      3\nChungbuk     3\nChungnam     6\nJeonbuk      1\nJeonnam      0\nGyeongbuk    2\nGyeongnam    0\nJeju         2\nName: 2020_bad, dtype: int64\n\n\n\n# '2020년 미세먼지 나쁨' 일수를 기준으로 오름차순 정렬\ndata2020_bad.sort_values(inplace=True)\ndata2020_bad\n\narea\nGwangju      0\nGyeongnam    0\nJeonnam      0\nDaejeon      1\nJeonbuk      1\nJeju         2\nBusan        2\nIncheon      2\nUlsan        2\nGyeongbuk    2\nGangwon      3\nChungbuk     3\nDaegu        4\nSejong       4\nSeoul        5\nChungnam     6\nGyeonggi     6\nName: 2020_bad, dtype: int64\n\n\n\ntype(data2020_bad)\n\npandas.core.series.Series\n\n\n\n# 가로형 막대 그래프 : 2020년 시도별 미세먼지(PM10) 나쁨 일수 비교\nplt.figure(figsize=(4, 4))\nplt.title('2020 Fine Dust(PM10) - Bay Days By Area')\nplt.barh(data2020_bad.index, data2020_bad)\nplt.xlabel('Count')\nplt.ylabel('Area')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 특·광역시의 '2017-2020년 미세먼지 보통' 일수만 가져오기\ndata4 = data.copy()\ndata4 = data4.loc['Seoul':'Ulsan', '2017_common':'2020_common']\ndata4\n\n\n\n\n\n\n\n\n2017_common\n2018_common\n2019_common\n2020_common\n\n\narea\n\n\n\n\n\n\n\n\nSeoul\n230\n204\n198\n193\n\n\nBusan\n269\n212\n193\n156\n\n\nDaegu\n244\n196\n200\n186\n\n\nIncheon\n264\n207\n227\n182\n\n\nGwangju\n216\n193\n227\n156\n\n\nDaejeon\n268\n219\n198\n183\n\n\nUlsan\n250\n184\n181\n158\n\n\n\n\n\n\n\n\n# 누적 막대 그래프 : 2017-2020 특·광역시 미세먼지(PM10) 보통 일수 비교\nplt.figure(figsize=(8, 3))\nplt.title('2017-2020 Fine Dust(PM10) - Common Days By Major City')\n\nindex = np.arange(7)\nleft = np.zeros(len(data4))\nfor year in data4.columns:\n    plt.barh(index, data4[year], left=left, label=year.split(\"_\")[0])\n    left = left + data4[year]\n\nplt.xlim(0, 1000)\nplt.xlabel('Count')\nplt.ylabel('Area')\nplt.yticks(index, data4.index)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "2_3_matplotlib.html#산점도",
    "href": "2_3_matplotlib.html#산점도",
    "title": "\n\nMatplotlib\n",
    "section": "5.5. 산점도",
    "text": "5.5. 산점도\n\n두 수치형 변수 간 관계를 시각화할 때 사용함\n데이터의 분포, 이상값, 변수 간 상관관계, 그룹화된 패턴 등을 직관적으로 파악할 수 있음\n\n\n\n[데이터] 캐글에서 제공하는 붓꽃 데이터\n\nSepalLength(꽃받침 길이), SepalWidth(꽃받침 너비), PetalLength(꽃잎 길이), PetalWidth(꽃잎 너비), Species(품종)\n[실습파일] 04_data2.csv\n\n\n\n\n# 데이터 불러오기\ndata = pd.read_csv('./data/04_data2.csv')\ndata.head()\n\n\n\n\n\n\n\n\nSepalLength\nSepalWidth\nPetalLength\nPetalWidth\nSpecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\n\n# 산점도1 : 꽃잎 길이와 꽃잎 너비의 관계\n# 꽃잎 길이가 길수록 꽆잎 너비도 대체로 증가하는 경향이 있음\nplt.figure(figsize=(4, 4))\nplt.title('Petal Length vs Width')\nplt.scatter(data['PetalLength'], data['PetalWidth'])\nplt.xlabel('Petal Length')\nplt.ylabel('Petal Width')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 산점도2 : 꽃잎 길이와 꽃잎 너비, 품종의 관계\n# 각 품종별로 꽃잎 길이와 너비가 뚜렷이 구분됨\n# setosa는 작고 좁은 꽃잎, virginica는 크고 넓은 꽃잎을 가짐\nplt.figure(figsize=(4, 4))\nplt.title('Petal Length vs Width By Species')\nplt.scatter(data['PetalLength'], data['PetalWidth'], alpha = 0.5,\n            c=data['Species'].map({'setosa': 'red', 'versicolor': 'green', 'virginica': 'blue'}))\nplt.xlabel('Petal Length')\nplt.ylabel('Petal Width')\nplt.show()"
  },
  {
    "objectID": "2_3_matplotlib.html#히스토그램",
    "href": "2_3_matplotlib.html#히스토그램",
    "title": "\n\nMatplotlib\n",
    "section": "5.6. 히스토그램",
    "text": "5.6. 히스토그램\n\n수치형 변수의 분포를 시각화할 때 사용함\n데이터를 일정한 구간(bin)으로 나누고, 각 구간에 속하는 값들의 빈도를 막대의 높이로 나타냄\n\n\n\n# 히스토그램 : setosa 품종의 꽃잎 길이 분포\n# setosa 품종의 꽃잎 길이는 1.0~1.9cm 사이에 분포함\n# 데이터는 대부분 1.5cm 주변에 집중되어 있으며, 대칭에 가까운 형태로 나타남\nsetosa = data.loc[data['Species']=='setosa',]\n\nplt.figure(figsize=(5, 3))\nplt.title('Distribution of Petal Length in Iris Setosa')\nplt.hist(setosa['PetalLength'], bins=8, edgecolor='black')\nplt.xlabel('Petal Length')\nplt.ylabel('Count')\nplt.show()"
  },
  {
    "objectID": "2_3_matplotlib.html#상자수염-그래프",
    "href": "2_3_matplotlib.html#상자수염-그래프",
    "title": "\n\nMatplotlib\n",
    "section": "5.7. 상자수염 그래프",
    "text": "5.7. 상자수염 그래프\n\n수치형 변수의 분포를 시각화할 때 사용함\n다섯 숫자 요약값을 기반으로 이상값, 분포의 비대칭 여부 등을 직관적으로 파악할 수 있음\n\n\n\n\n\n# 상자수염 그래프 : 꽃받침 길이와 너비의 분포 비교\n# 꽃받침 길이는 꽃받침 너비보다 전체적으로 큰 값을 가지며, 변동 폭도 더 큼\n# 꽃받침 너비는 상대적으로 산포가 작고, 일부 이상값(outlier)이 존재함\nplt.figure(figsize=(5, 3))\nplt.boxplot([data['SepalLength'], data['SepalWidth']],\n            tick_labels=['Sepal Length', 'Sepal Width'],\n            vert=False, widths=0.5)\nplt.title('Sepal Length and Width')\nplt.show()"
  },
  {
    "objectID": "2_1_numpy.html",
    "href": "2_1_numpy.html",
    "title": "\n\nNumPy\n",
    "section": "",
    "text": "NumPy"
  },
  {
    "objectID": "2_1_numpy.html#넘파이-배열",
    "href": "2_1_numpy.html#넘파이-배열",
    "title": "\n\nNumPy\n",
    "section": "3.1. 넘파이 배열",
    "text": "3.1. 넘파이 배열\n\nNumPy 라이브러리\n\nNumerical Python의 약자로, 과학적 연산과 수치 계산을 위한 Python 라이브러리\n대규모 다차원 배열 및 행렬 연산에 최적화되어 있으며, 빠르고 효율적인 데이터 처리를 지원함\n\n\n\n\n넘파이 배열(ndarray)\n\n동일한 자료형의 요소들로 구성된 다차원 배열\n일반적인 리스트보다 메모리 효율이 뛰어나고, 연산 속도도 훨씬 빠름\n순서가 있는(ordered) 구조로, 인덱싱과 슬라이싱을 통해 요소 접근 및 수정이 가능함\n\n\n\n\n# NumPy 라이브러리 설치\n#!pip install numpy\n\n\n# NumPy 라이브러리 불러오기\nimport numpy as np\n\n\n# 넘파이 배열 생성1 : 리스트 사용\narr = np.array([1, 2, 3, 4])\nprint(arr)\n\n[1 2 3 4]\n\n\n\n# 넘파이 배열 생성2\n# 하나의 배열에는 동일한 자료형만 저장할 수 있음\n# 만약 숫자와 문자를 동시에 배열에 넣으면 모두 문자열로 취급됨\narr = np.array([1, 2, \"A\"])\nprint(arr)\n\n['1' '2' 'A']\n\n\n\n# 넘파이 배열 생성3 : 2차원 배열\n# 리스트를 중첩해서 인수로 넘겨 2차원 배열을 만듬\narr = np.array([[1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10]])\nprint(arr)\n\n[[ 1  2  3  4  5]\n [ 6  7  8  9 10]]\n\n\n\n# 넘파이 배열 속성1 : 배열의 차원\narr.ndim\n\n2\n\n\n\n# 넘파이 배열 속성2 : 배열 요소의 자료형\narr.dtype\n\ndtype('int32')\n\n\n\n# 넘파이 배열 속성3 : 배열 요소의 byte 수\narr.itemsize\n\n4\n\n\n\n# 넘파이 배열 속성4 : 배열 요소의 개수\narr.size\n\n10\n\n\n\n# 넘파이 배열 속성5 : 배열 전체의 byte 수\narr.nbytes\n\n40\n\n\n\n# 넘파이 배열 속성6 : 배열의 모양(행, 열)\narr.shape\n\n(2, 5)\n\n\n\n# 넘파이 배열 속성7 : 전치(transpose)\narr.T\n\narray([[ 1,  6],\n       [ 2,  7],\n       [ 3,  8],\n       [ 4,  9],\n       [ 5, 10]])\n\n\n\n\nNumPy 라이브러리의 arange() 함수를 이용하여 등차수열을 생성할 수 있음\n\nstart : 시작 값\nstop : 끝 값 (포함하지 않음)\nstep : 차이 값; 간격(stride)\n\n\n\n\nnumpy.arange(start, stop, step)\n\n\n\n# 등차수열 생성1 : 0부터 n-1까지 정수\narr = np.arange(5)\nprint(arr)\n\n[0 1 2 3 4]\n\n\n\n# 등차수열 생성2 : 시작 값, 끝 값 지정\narr = np.arange(2, 10)\nprint(arr)  \n\n[2 3 4 5 6 7 8 9]\n\n\n\n# 등차수열 생성3 : 간격 지정\narr = np.arange(1, 10, 2)\nprint(arr)\n\n[1 3 5 7 9]\n\n\n\n# 등차수열 생성4 : 실수(float) 간격 지정\narr = np.arange(0, 1, 0.2)\nprint(arr)\n\n[0.  0.2 0.4 0.6 0.8]"
  },
  {
    "objectID": "2_1_numpy.html#넘파이-배열-인덱싱",
    "href": "2_1_numpy.html#넘파이-배열-인덱싱",
    "title": "\n\nNumPy\n",
    "section": "3.2. 넘파이 배열 인덱싱",
    "text": "3.2. 넘파이 배열 인덱싱\n\n넘파이 배열은 정수, 배열, 논리값(boolean) 등으로 인덱싱할 수 있음\n리스트 인덱싱과 마찬가지로 []를 사용하며, 인덱스는 0부터 시작\n마스킹(masking), 논리값 인덱싱(boolean indexing)\n\n특정 조건에 맞는 데이터를 추출하는 것\n일반적으로 비교 연산자를 사용한 조건식을 사용함\n특히 데이터가 많을 때 반복문 없이 조건 검사가 가능하여 효율적임\n\n\n\n\n# 정수 인덱싱\narr = np.array([10, 20, 30, 40, 50])\nprint(arr[1])\nprint(arr[-2])\n\n20\n40\n\n\n\n# 배열 인덱싱\nidx = np.array([0, 2])\nprint(arr[idx])\n\n[10 30]\n\n\n\n# 논리값(boolean) 인덱싱 : 조건을 만족하는 값 추출\nmask = np.array([True, False, True, True, False])\nprint(arr[mask])\nprint(arr[arr &gt; 25])\n\n[10 30 40]\n[30 40 50]"
  },
  {
    "objectID": "2_1_numpy.html#넘파이-배열-슬라이싱",
    "href": "2_1_numpy.html#넘파이-배열-슬라이싱",
    "title": "\n\nNumPy\n",
    "section": "3.3. 넘파이 배열 슬라이싱",
    "text": "3.3. 넘파이 배열 슬라이싱\n\n넘파이 배열에서 연속된 일부 요소를 잘라 추출하는 것\n[start:stop:step]를 사용하여 범위를 지정함\n\nstart : 시작 인덱스\nstop : 끝 인덱스 (포함하지 않음)\nstep : 증감 폭\n\n\n\n\n# 배열 슬라이싱1 : 1번 인덱스부터 4번 인덱스 전까지\narr = np.array([11, 12, 13, 14, 15])\nprint(arr[1:4])\n\n[12 13 14]\n\n\n\n# 배열 슬라이싱2 : 처음부터 3번 인덱스 전까지\nprint(arr[:3])\n\n[11 12 13]\n\n\n\n# 배열 슬라이싱3 : 2번 인덱스부터 끝까지\nprint(arr[2:])            # [30 40 50] ()\n\n[13 14 15]\n\n\n\n# 배열 슬라이싱4 : 요소를 2개씩 건너뛰기\nprint(arr[::2])\n\n[11 13 15]\n\n\n\n# 배열 슬라이싱5 : 역순 정렬\nprint(arr[::-1])\n\n[15 14 13 12 11]"
  },
  {
    "objectID": "2_1_numpy.html#브로드캐스팅",
    "href": "2_1_numpy.html#브로드캐스팅",
    "title": "\n\nNumPy\n",
    "section": "3.4. 브로드캐스팅",
    "text": "3.4. 브로드캐스팅\n\n브로드캐스팅(broadcasting)\n\n서로 다른 형태의 배열 간 연산을 할 때 발생함\n작은 차원의 배열을 큰 차원의 배열에 맞게 자동으로 변환한 후, 요소별로 연산을 수행함\n\n\n\n\n\n# 넘파이 배열 연산 : 동일한 위치의 요소 간 연산 숭행\narr1 = np.array([1, 2, 3])\narr2 = np.array([10, 20, 30])\narr1 + arr2\n\narray([11, 22, 33])\n\n\n\n# 넘파이 배열 연산 : 브로드캐스팅\narr = np.array([1, 2, 3, 4])\nprint(arr + 2)\nprint(arr * 2)\n\n[3 4 5 6]\n[2 4 6 8]"
  },
  {
    "objectID": "2_1_numpy.html#배열-정렬",
    "href": "2_1_numpy.html#배열-정렬",
    "title": "\n\nNumPy\n",
    "section": "3.5. 배열 정렬",
    "text": "3.5. 배열 정렬\n\nnp.sort(배열) : 배열을 오름차순 정렬한 새로운 배열을 반환, 원본은 변하지 않음\n배열.sort() : 배열을 오름차순 정렬하고, 원본 자체를 변경함\nnp.argsort(배열) : 정렬 시 각 요소가 위치하게 될 인덱스의 배열을 반환\n\n\n\n# 배열 정렬1\narr = np.array([3, 2, 5, 1, 4])\nprint(np.sort(arr))\nprint(arr)\n\n[1 2 3 4 5]\n[3 2 5 1 4]\n\n\n\n# 배열 정렬2\narr.sort()\nprint(arr)\n\n[1 2 3 4 5]\n\n\n\n# 배열 정렬3\narr = np.array([3, 2, 5, 1, 4])\nprint(np.argsort(arr))\n\n[3 1 0 4 2]"
  },
  {
    "objectID": "2_1_numpy.html#얕은-복사와-깊은-복사",
    "href": "2_1_numpy.html#얕은-복사와-깊은-복사",
    "title": "\n\nNumPy\n",
    "section": "3.6. 얕은 복사와 깊은 복사",
    "text": "3.6. 얕은 복사와 깊은 복사\n\n얕은 복사\n\n= 연산자 또는 view() 메소드를 사용한 복사\n데이터의 메모리 주소만 복사하여, 원본과 데이터를 공유함\n원본이나 복사본 중 하나를 수정하면 서로 영향을 미침\n\n\n\n\n깊은 복사\n\ncopy() 메소드를 사용한 복사\n완전히 새로운 메모리 공간에 데이터 전체를 복사함\n원본과 복사본이 독립적이며, 어느 쪽을 수정해도 서로 영향을 주지 않음\n\n\n\n\n# 얕은 복사\narr1 = np.arange(6)\ncopy1 = arr1\n\nprint(arr1)\nprint(copy1)\n\n[0 1 2 3 4 5]\n[0 1 2 3 4 5]\n\n\n\n# 복사본을 수정하면 원본도 변함\ncopy1[0] = 10\nprint(arr1)\nprint(copy1)\n\n[10  1  2  3  4  5]\n[10  1  2  3  4  5]\n\n\n\n# 깊은 복사\narr2 = np.arange(6)\ncopy2 = arr2.copy()\n\nprint(arr2)\nprint(copy2)\n\n[0 1 2 3 4 5]\n[0 1 2 3 4 5]\n\n\n\n# 복사본을 수정해도 원본이 변하지 않음\ncopy2[0] = 20\nprint(arr2)\nprint(copy2)\n\n[0 1 2 3 4 5]\n[20  1  2  3  4  5]"
  },
  {
    "objectID": "1_1_environment.html",
    "href": "1_1_environment.html",
    "title": "\n\nPython 개발 환경\n",
    "section": "",
    "text": "Python 개발 환경"
  },
  {
    "objectID": "1_1_environment.html#python-소개",
    "href": "1_1_environment.html#python-소개",
    "title": "\n\nPython 개발 환경\n",
    "section": "1.1. Python 소개",
    "text": "1.1. Python 소개\n\n컴퓨터 프로그램과 프로그래밍 언어\n\n컴퓨터 프로그램 (computer program) : 컴퓨터로 문제를 해결하기 위해 작성하는 명령어의 모음\n프로그래밍 언어(programming language)\n\n컴퓨터에 어떤 동작을 수행하도록 지시하는 언어\n프로그래밍 언어를 사용하여 프로그램을 논리적으로 작성하는 작업을 코딩(coding)이라 함\n\n\n\n\n\nPython\n\n1991년 귀도 반 로섬(Guido van Rossum)이 개발한 프로그래밍 언어\n빅데이터 분석과 인공지능 분야에서 가장 널리 사용되고 있음\n문법이 쉽고 간결하여 프로그래밍을 처음 접하는 사람이 배우기 적합함\n\n\n\n\nPython 특징\n\n플랫폼 독립적인 언어 : 컴퓨터 운영체제나 하드웨어의 종류에 관계없이 사용할 수 있음\n인터프리터 언어 : 소스코드 자체가 바로 실행되어 간편하게 사용할 수 있음(속도는 느림)\n동적 타이핑 언어\n\n프로그램의 실행 시점에서 각 프로그램 변수의 타입(type)을 결정하는 언어\n인터프리터 언어이므로 프로그램의 실행 시점에 변수들의 메모리 공간을 자유롭게 할당받을 수 있음\n\n객체 지향 언어\n\n프로그램이 해결해야 할 문제의 구성요소를 요소별로 정의한 다음, 각 요소의 기능(method)과 정보(attribute)를 프로그래밍한 다음 요소들을 결합하는 방식으로 프로그램을 작성함\n이때 각 요소를 객체(object)라고 하며, 한 번 만들어진 객체는 재사용(reusability)할 수 있음"
  },
  {
    "objectID": "1_1_environment.html#python-설치",
    "href": "1_1_environment.html#python-설치",
    "title": "\n\nPython 개발 환경\n",
    "section": "1.2. Python 설치",
    "text": "1.2. Python 설치\n\n1.2.1. Jupyter Lab\n\nJupyter Notebook\n\n가장 많이 사용되는 Python IDE 중 하나로, 웹 브라우저에서 실행되는 대화형 개발 도구\n코드 작성 및 실행, 텍스트(Markdown), 수식(LaTeX), 그래프(Matplotlib) 등을 한 화면에서 통합적으로 작성 가능\n셀 단위로 실행 결과를 저장하여 분석 과정을 논리적으로 정리하고, 문서화 및 공유가 용이함\n\n\n\n\nJupyter Lab\n\nJupyter Notebook을 확장한 차세대 인터페이스\n탭(tab) 기반 인터페이스, 파일 브라우저, 터미널, Markdown 편집기 등 통합 개발 환경을 제공함\n여러 노트북, 텍스트 파일, 콘솔 등을 동시에 열고 작업할 수 있어 워크플로우가 유연함\nJupyter Notebook과 호환되며, 확장 플러그인을 통해 다양한 기능을 자유롭게 추가할 수 있음\n\n\n\n\n가상 환경(virtual environment)\n\n하나의 컴퓨터에서 프로젝트마다 독립적인 작업 공간을 제공함\nPython 및 라이브러리의 버전을 프로젝트별로 분리해 설칠할 수 있어, 의존성 출돌을 방지하고 관리가 용이함\n재현 가능한 실행 환경을 제공하여 코드의 안정성을 높이고 협업에 유리함\n\n\n\n\nJupyter Lab 실행을 위한 환경 설정\n\nAnaconda3 설치\nAnaconda Prompt 실행\n가상 환경 생성 : conda create -n myenv python=3.11\n가상 환경 리스트 조회 : conda info --envs\n가상 환경 접속(활성화) : conda activate myenv\n(가상 환경에서) Jupyter Lab 설치 : conda install -c conda-forge jupyterlab\nJupyter Lab 실행 : jupyter lab\n\n\n\n\n\n1.2.2. Google Colab\n\nGoogle Colab\n\n구글에서 제공하는 클라우드 기반의 Jupyter Notebook 개발 환경으로, 웹 브라우저에서 Python 코드 작성 및 실행이 가능함\n별도의 설치 없이 바로 사용할 수 있으며, 구글 드라이브와 연동하여 작성한 파일을 클라우드에 저장하고 쉽게 관리할 수 있음\n다양한 라이브러리(Numpy, Pandas, Matplotlib 등)가 기본적으로 설치되어 있음\nGPU, TPU 지원을 통해 대규모 데이터 처리와 딥러닝 모델 학습에 유리함\n협업 기능을 제공하여, 여러 사람이 동시에 실시간으로 작업하고 프로그램을 공유할 수 있음"
  },
  {
    "objectID": "1_1_environment.html#문서화-및-공유",
    "href": "1_1_environment.html#문서화-및-공유",
    "title": "\n\nPython 개발 환경\n",
    "section": "1.3. 문서화 및 공유",
    "text": "1.3. 문서화 및 공유\n\n1.3.1. Markdown 문법\n\nMarkdown\n\n일반 텍스트 기반의 경량 마크업 언어(markup language)\n특수 기호와 문자를 이용한 간단하고 직관적인 문법으로 웹 콘텐츠를 빠르게 작성할 수 있음\n[참고] 마크업 언어 : 태그(tag) 등을 이용하여 문서나 데이터의 구조를 명시하는 언어의 일종\n\n\n\n\n제목(Header)\n\n# First-level Header\n## Second-level Header\n### Third-level Header\n#### Fourth-level Header\n##### Fifth-level Header\n###### Sixth-level Header\n\n\n인용(Quote)\n\n&gt; \"Blaze with the fire that is never extinguished.\"\n\n\n목록(List)\n\n1. Item 1\n2. Item 2\n3. Item 3\n* Item 1\n+ Item 2\n- Item 3\n  * Item 3a\n  + Item 3b\n  - Item 3c\n\n\n수평선(Line)\n\n---\n***\n\n\n강조(Emphasis)\n\n*italic*\n_italic_\n**bold**\n__bold__\n~~strikethrough~~\n\n\n인라인 코드(Inline Code)\n\nWe defined the `add` function to compute the sum of two numbers.\n\n\n고정된 코드 블록(Plain Code Blocks)\n\n```\nThis text is displayed verbatim / preformatted\n```\n\n\n\n1.3.2. Quarto 프로젝트 생성\n\nQuarto\n\n웹사이트, 문서, 슬라이드, 대시보드 등을 제작할 수 있는 통합 문서 작성 도구\nPython, R, Julia 등 다양한 언어를 지원하며, 실행과 동시에 문서화가 가능함\nHTML, PDF, MS Word, ePub 등 다양한 형식으로 변환하여 출력할 수 있음\nGit을 통한 버전 관리, Git Pages와의 연계를 통해 문서를 손쉽게 공유할 수 있음\n\n\n\n\nQuarto 프로젝트 생성\n\nQuarto 설치\n\nQuarto 다운로드\nAnaconda Prompt에서 설치 확인 : quarto --version\n\nQuarto 프로젝트 생성\n\nAnaconda Prompt에서 Quarto 프로젝트를 생성할 폴더로 이동 : cd \"C:\\Users\\user\"\nQuarto 프로젝트 생성 : quarto create-project ml-project --type website\n\nQuarto 프로젝트 작성\n\n_quarto.yml 수정\n\nHTML Theming\n\nJupyter Notebook 작성 : myproject.ipynb\n.ipynb 파일을 .qmd 파일로 변환\n\nAnaconda Prompt에서 Quarto 프로젝트 폴더로 이동 : cd ml-project\n.qmd 파일로 변환(선택) : quarto convert myproject.ipynb -o myproject.qmd\nHTML 파일 생성 : quarto render\n웹사이트 미리보기 : quarto preview\n\n\n\n\n\n\n_quarto.yml 파일\n\nproject:\n  type: website\n  output-dir: docs\n\nwebsite:\n  title: \"R&E 활동\"\n  navbar:\n    left:\n      - href: myproject.qmd\n        text: Project\n\nformat:\n  html:\n    theme:\n      - cerulean\n    css: styles.css\n    toc: true\n\n\n\n1.3.3. Git Pages 배포\n\nGit Pages\n\nGitHub에서 HTML 문서를 무료로 웹사이트 형태로 배포할 수 있는 서비스\n설정이 간단하며, Git과 통합되어 버전 관리와 팀 작업에 효율적임\n\n\n\n\nGit Pages 배포\n\nGitHub 계정 및 저장소(repository) 생성\nGit 설치\n\nGit 다운로드\nAnaconda Prompt에서 설치 확인 : git --version\n\nGit 사용자 정보 설정(공용 컴퓨터에서 local 설정)\n\nQuarto 프로젝트 폴더로 이동 : cd ml-project\ngit config user.name \"Name\"\ngit config user.email \"address@email.com\"\n설정 확인 : git config --local --list\n\nGit Pages 배포\n\nGit 초기화 : git init\n기본 branch를 main으로 변경 : git branch -m master main\n파일 추가 : git add -A\n변경 내용 저장 : git commit -m \"Initial commit\"\nGitHub 원격 저장소 연결 : git remote add origin https://github.com/stat6503/ml-project.git\n원격 저장소 연결 확인 : git remote -v\nGitHub에 업로드 : git push -u origin main\nGitHub 설정 수정\n\nGitHub → Repository → Setting → Pages → Branch: main, Folder: /docs\n\n\nGit Pages 확인\n\nhttps://stat6503.github.io/ml-project\n\n\n\n\n\n개인 컴퓨터에서 Git 사용자 정보 설정\n\nAnaconda Prompt, Git Bash에서\ngit config --global user.name \"Name\"\ngit config --global user.email \"address@email.com\"\n설정 확인 : git config --global --list\n\n\n\n\n공용 컴퓨터에서 개인 정보 삭제\n\nAnaconda Prompt에서 Quarto 프로젝트 폴더로 이동 : cd ml-project\n\ngit config --unset user.name\ngit config --unset user.email\ngit credential-manager clear\n\nQuarto 프로젝트 폴더 삭제"
  },
  {
    "objectID": "1_2_basic.html",
    "href": "1_2_basic.html",
    "title": "\n\n기초 문법\n",
    "section": "",
    "text": "기초 문법"
  },
  {
    "objectID": "1_2_basic.html#변수",
    "href": "1_2_basic.html#변수",
    "title": "\n\n기초 문법\n",
    "section": "2.1. 변수",
    "text": "2.1. 변수\n\n변수(variable)\n\n값을 저장하는 공간\n(할당) 변수명 = 값\n\n\n\n\n변수의 특징\n\n일시적으로 자료를 저장하는 공간으로, 변수에 저장된 값은 변할 수 있음\n숫자, 문자열 등 모든 자료형을 저장할 수 있고, 다른 변수의 값도 저장할 수 있음\n변수는 사용되기 전에 반드시 할당되어 있어야 함\n\n\n\n\n변수명 작성 규칙\n\n영문자, 숫자, _로 구성될 수 있으며, 첫 글자는 반드시 영문자나 _로 시작함\n공백을 포함할 수 없음\n대문자와 소문자를 구별함\nPython에서 다른 용도로 사용되는 예약어는 사용할 수 없음\n\n\n\n\n# 변수 생성1 : 숫자\na = 100\nprint(a)\n\n100\n\n\n\n# 변수 사용\nprint(a)\na = a + 50\nprint(a)\n\n100\n150\n\n\n\n# 변수 생성2 : 문자열\nname = '이순신'\naddr = \"서울시\"\nprint(name, addr)\n\n이순신 서울시\n\n\n\n# 예약어\nimport keyword\nprint(keyword.kwlist)\n\n['False', 'None', 'True', 'and', 'as', 'assert', 'async', 'await', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']\n\n\n\n\n[Note] 주석(comment)\n\n프로그램 안에서 코드가 아닌 텍스트로 작성되며, 프로그램 실행 시 무시됨\n코드의 기능을 설명하거나 알아야할 사항을 기록할 때 사용함\n한 줄 주석 처리 : # comment\n여러 줄 주석 처리 : ''' comment ''', \"\"\" comment \"\"\"\n\n\n\n\n[Note] 기본 자료형\n\n\n\n\n자료형\n의미\n예시\n\n\n\n\nint\ninteger, 정수\n100\n\n\nfloat\nfloat, 부동 소수점\n95.7\n\n\nstr\nstring, 문자열\n‘Lee’\n\n\nbool\nboolean, 부울\nTrue False\n\n\n\n\n\n# 기본 자료형\nprint(type(100))\nprint(type(95.7))\nprint(type('Lee'))\nprint(type(True))\nprint(type(False))\n\n&lt;class 'int'&gt;\n&lt;class 'float'&gt;\n&lt;class 'str'&gt;\n&lt;class 'bool'&gt;\n&lt;class 'bool'&gt;"
  },
  {
    "objectID": "1_2_basic.html#연산자",
    "href": "1_2_basic.html#연산자",
    "title": "\n\n기초 문법\n",
    "section": "2.2. 연산자",
    "text": "2.2. 연산자\n\n2.2.1. 산술 연산자\n\n\n\n연산자\n의미\n예시\n결과\n\n\n\n\n+\n더하기\n10+20\n30\n\n\n-\n빼기\n10-20\n-10\n\n\n*\n곱하기\n10*20\n200\n\n\n/\n나누기\n10/20\n0.5\n\n\n//\n나눈 정수 몫\n10//20\n0\n\n\n%\n나눈 나머지\n10%20\n10\n\n\n**\n거듭제곱\n10**2\n100\n\n\n\n\n\n\n2.2.2. 대입 연산자\n\n변수에 값을 할당(assignment)하는 연산자\n기본적으로 =를 사용하며, 산술 연산자와 함께 사용하면 할당을 보다 간결하게 할 수 있음\n\n\n\n\n\n\n\n\n\n연산자\n의미\n예시\n\n\n\n\n=\n왼쪽 변수에 오른쪽 값을 할당\nx=10\n\n\n+=\n왼쪽 변수에 오른쪽 값을 더하고 결과를 왼쪽 변수에 할당\nx+=10\n\n\n-=\n왼쪽 변수에 오른쪽 값을 빼고 결과를 왼쪽 변수에 할당\nx-=10\n\n\n*=\n왼쪽 변수에 오른쪽 값을 곱하고 결과를 왼쪽 변수에 할당\nx*=10\n\n\n/=\n왼쪽 변수에 오른쪽 값을 나눈 결과를 왼쪽 변수에 할당\nx/=10\n\n\n//=\n왼쪽 변수에 오른쪽 값을 나눈 몫의 결과를 왼쪽 변수에 할당\nx//=10\n\n\n%=\n왼쪽 변수에 오른쪽 값을 나눈 나머지의 결과를 왼쪽 변수에 할당\nx%=10\n\n\n**=\n왼쪽 변수에 오른쪽 값만큼 거듭제곱을 하고 결과를 왼쪽 변수에 할당\nx**=2\n\n\n\n\n\n\n2.2.3. 비교 연산자\n\n두 개 이상의 식 또는 변수의 비교를 위해 사용하는 연산자\n결과는 참(True) 또는 거짓(False)으로 나타남\n단독으로 사용되는 경우보다는 주로 조건문과 반복문에서 사용됨\n\n\n\n\n연산자\n의미\n예시\n결과\n\n\n\n\n==\n값이 동일하다\n10==20\nFalse\n\n\n!=\n값이 동일하지 않다\n10!=20\nTrue\n\n\n&gt;\n왼쪽 값이 오른쪽 값보다 크다\n10&gt;20\nFalse\n\n\n&gt;=\n왼쪽 값이 오른쪽 값보다 크거나 동일하다\n10&gt;=20\nFalse\n\n\n&lt;\n왼쪽 값이 오른쪽 값보다 작다\n10&lt;20\nTrue\n\n\n&lt;=\n왼쪽 값이 오른쪽 값보다 작거나 동일하다\n10&lt;=20\nTrue\n\n\n\n\n\n\n2.2.4. 논리 연산자\n\n참(True)과 거짓(False)의 논리 동작을 다루는 연산자\n여러 조건을 조합할 때 주로 사용됨\n\n\n\n\n\n\n\n\n\n\n연산자\n의미\n예시\n결과\n\n\n\n\nand\n논리 AND 연산, 왼쪽 식과 오른쪽 식 모두 참인 경우에만 True\na=25 print(a&gt;8 and a&lt;60)\nTrue\n\n\nor\n논리 OR 연산, 왼쪽 식과 오른쪽 식 중 하나라도 참인 경우에만 True\na=70 print(a&lt;8 or a&gt;=60)\nTrue\n\n\nnot\n논리 NOT 연산, 오른쪽 식이 참이면 False, 거짓이면 True\na=20 print(not a==20)\nFalse"
  },
  {
    "objectID": "1_2_basic.html#표준-입출력",
    "href": "1_2_basic.html#표준-입출력",
    "title": "\n\n기초 문법\n",
    "section": "2.3. 표준 입출력",
    "text": "2.3. 표준 입출력\n\n표준 입력\n\n사용자로부터 값을 입력받기 위해 input() 함수를 사용함\ninput() 함수는 안내문을 출력한 후 사용자의 입력을 기다리며, 입력한 값을 문자열로 저장함\n입력한 값을 숫자로 사용하려면 int(), float() 함수를 이용하여 형 변환해야 함\n변수 = input(안내문)\n\n\n\n\n표준 출력\n\n값을 출력하기 위해 print() 함수를 사용함\n여러 값을 ,로 구분하여 출력할 수 있음\nf-string 포맷팅\n\n문자열 맨 앞에 f를 붙이고 {} 안에 변수명을 직접 작성하여 출력하는 방식\n가독성이 좋고 사용 방법이 간단하여 자주 사용됨\n\n\n\n\n\n# 표준 입출력\n#x = int(input('첫 번째 숫자 입력 : '))\n#y = int(input('두 번째 숫자 입력 : '))\n#print('두 수의 합 : ', x, ' + ', y, ' = ', x+y)\n\n\n# f-string 포맷팅\n#print(f'두 수의 차 : {x} - {y} = {x-y}')"
  },
  {
    "objectID": "1_2_basic.html#컬렉션-자료형",
    "href": "1_2_basic.html#컬렉션-자료형",
    "title": "\n\n기초 문법\n",
    "section": "2.4. 컬렉션 자료형",
    "text": "2.4. 컬렉션 자료형\n\n2.4.1. 컬렉션 자료형\n\n컬렉션 자료형(collection data type)\n\n여러 개의 값을 하나의 변수에 저장할 수 있는 자료형\n대표적으로 리스트(list), 튜플(tuple), 딕셔너리(dictionary), 세트(set)가 있음\n\n\n\n\n\n2.4.2. 리스트\n\n리스트(list)\n\n여러 개의 값을 저장할 수 있는 자료구조로, [] 안에 값을 ,로 구분하여 나열함\n숫자형, 문자열, 리스트 등 서로 다른 자료형을 함께 저장할 수 있음\n순서가 있는(ordered) 구조로, 인덱스(index)를 통해 각 요소에 접근할 수 있음\n\n인덱싱(indexing) : [index]를 사용하여 리스트의 특정 위치에 있는 요소에 접근함\n슬라이싱(slicing) : [start:stop]를 사용하여 리스트의 일부 요소에 접근함\n\n한 번 생성한 후에도 값을 추가, 변경, 삭제할 수 있음\n\n\n\n\n# 리스트 생성1\nx = [10, 20, 30]\nprint(x)\n\n[10, 20, 30]\n\n\n\n# 리스트 생성2\ny = [3.14, 'Park', [1, 2, 3], x]\nprint(y)\n\n[3.14, 'Park', [1, 2, 3], [10, 20, 30]]\n\n\n\n# 리스트 인덱싱1 : 첫 번째 값 가져오기\nx = [15, 25, 35, 45]\nx[0]\n\n15\n\n\n\n# 리스트 인덱싱2 : 마지막 값 가져오기\nx[-1]\n\n45\n\n\n\n# 리스트 슬라이싱1 : (stop index)는 포함하지 않음\nx = [10, 20, 30, [40, 50]]\nx[0:2]\n\n[10, 20]\n\n\n\n# 리스트 슬라이싱2\nx[1:]\n\n[20, 30, [40, 50]]\n\n\n\n# 리스트 슬라이싱3\nx[:2]\n\n[10, 20]\n\n\n\n# 리스트 슬라이싱4 : 이중 리스트 슬라이싱\nprint(x[3])\nprint(x[3][0])\n\n[40, 50]\n40\n\n\n\n# 리스트 변경\nx = [10, 20, 30]\nprint(x)\n\nx[0] = 50\nprint(x)\n\nx[1:3] = [90, 100]\nprint(x)\n\n[10, 20, 30]\n[50, 20, 30]\n[50, 90, 100]\n\n\n\n\n\n2.4.3. 튜플\n\n튜플(tuple)\n\n여러 개의 값을 저장할 수 있는 자료구조로, () 안에 값을 ,로 구분하여 나열함\n대부분 리스트와 비슷하지만, 한 번 저장한 값은 수정할 수 없음\n\n\n\n\n# 튜플 생성1 : 빈 튜플 생성\nx = ()\nprint(x)\n\n()\n\n\n\n# 튜플 생성2\nx = (1, 2, 3)\nprint(x)\n\n(1, 2, 3)\n\n\n\n# 튜플 생성3 : ()를 생략할 수 있음\nx = 1, 2, 3\nprint(x)\n\n(1, 2, 3)\n\n\n\n# 튜플 생성4 : 0에서 9까지 정수 생성\nx = tuple(range(10))\nprint(x)\n\n(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n\n\n# 튜플 생성5 : 리스트를 튜플로 자료형 변환\nx = ['월', '화', '수', '목', '금', '토', '일']\nx = tuple(x)\nprint(x)\n\n('월', '화', '수', '목', '금', '토', '일')\n\n\n\n# 튜플 변경 : Error!\n#x = (10, 20, 30)\n#x[0] = 100\n\n\n# 튜플 인덱싱\nx = (10, 20, 30, 40)\nx[-1]\n\n40\n\n\n\n# 튜플 슬라이싱\nx[:2]\n\n(10, 20)\n\n\n\n\n\n2.4.4. 딕셔너리\n\n딕셔너리(dictionary)\n\n연관된 값을 키-값(key-value) 쌍으로 저장하는 자료구조로, {} 안에 key: value 값을 ,로 구분하여 나열함\n리스트나 튜플과 달리, 인덱스가 아닌 키(key)를 통해 값(value)에 접근함\n\n\n\n\n# 딕셔너리 생성1 : 빈 딕셔너리 생성\nx = {}\nprint(x)\n\n{}\n\n\n\n# 딕셔너리 생성2\nmenu = {'김밥': 3000, '라면': 5000}\nprint(menu)\n\n{'김밥': 3000, '라면': 5000}\n\n\n\n# 딕셔너리 요소 접근1\nmenu['김밥']\n\n3000\n\n\n\n# 딕셔너리 요소 접근2\nmenu['어묵'] = 1500\nprint(menu)\n\n{'김밥': 3000, '라면': 5000, '어묵': 1500}\n\n\n\n# 딕셔너리 요소 접근3 : Error!\n#menu['순대']\n\n\n\n\n2.4.5. 세트\n\n세트(set)\n\n집합에 관련된 것을 쉽게 처리하게 만든 자료구조로, {} 안에 값을 ,로 구분하여 나열함\n중복을 허용하지 않으며, 순서가 없어 인덱스로 각 요소에 접근할 수 없음\n\n\n\n\n# 세트 생성1\nx = {10, 20, 30, 10}\nprint(x)\n\n{10, 20, 30}\n\n\n\n# 세트 생성2\nx = set([10, 20, 30])\nprint(x)\n\n{10, 20, 30}"
  },
  {
    "objectID": "1_2_basic.html#리스트-컴프리헨션",
    "href": "1_2_basic.html#리스트-컴프리헨션",
    "title": "\n\n기초 문법\n",
    "section": "2.5. 리스트 컴프리헨션",
    "text": "2.5. 리스트 컴프리헨션\n\n리스트 컴프리헨션(list comprehension)\n\n원하는 자료들을 조회 또는 추출하여 리스트로 변환하는 표현식\n조건식을 이용하여 같은 연산을 전체 항목이나 일부 항목에 적용할 수 있음\n\n\n\n\n[표현식 for 변수 in 항목들 if 조건]\n\n\n\n리스트 컴프리헨션 처리 과정\n\n항목들을 순차적으로 하나씩 꺼내옴\n조건식을 적용하여 해당 조건에 맞는 항목은 추출하고, 조건에 맞지 않으면 무시함\n위에서 추출한 항목을 리스트에 추가함\n\n\n\n\n# 리스트 컴프리헨션1 : 조건이 없는 경우\nnum = [-20, -10, 0, 0, 10, 20]\n[x+5 for x in num]\n\n[-15, -5, 5, 5, 15, 25]\n\n\n\n# 리스트 컴프리헨션2 : 조건이 있는 경우\n[1/x for x in num if x&gt;0]\n\n[0.1, 0.05]"
  },
  {
    "objectID": "1_2_basic.html#선택문",
    "href": "1_2_basic.html#선택문",
    "title": "\n\n기초 문법\n",
    "section": "2.6. 선택문",
    "text": "2.6. 선택문\n\n선택문\n\nif 문을 이용하여 조건식이 True일 때만 코드를 실행하는 선택 구조\n\n\n   \n\n# 무작위로 1~100 사이의 두 정수를 생성한 후, 큰 수부터 작은 수 순으로 출력\nimport random\na = random.randint(1, 100)\nb = random.randint(1, 100)\n\nif a&lt;b:\n    a, b = b, a\n\nprint(a, b)\n\n16 15"
  },
  {
    "objectID": "1_2_basic.html#반복문",
    "href": "1_2_basic.html#반복문",
    "title": "\n\n기초 문법\n",
    "section": "2.7. 반복문",
    "text": "2.7. 반복문\n\n반복문\n\n일정한 횟수나 조건식을 만족하는 동안 코드를 반복 실행하는 제어 구조\nfor 문 : 주어진 범위만큼 코드를 반복 실행\nwhile 문 : 조건식이 True인 동안 코드를 반복하다가, False가 되면 종료\n\n\n  \n\n# for 문 : 문자열을 3번 반복해서 출력\nfor i in range(3):\n    print(\"Hello!\")\n\nHello!\nHello!\nHello!\n\n\n\n# for 문 : 반복범위의 값을 출력\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\n# while 문 : 1~100 정수의 합 계산\nsum = 0\nnum = 1\n\nwhile num &lt;= 100:\n    sum += num\n    num += 1\n\nprint(sum)\n\n5050"
  },
  {
    "objectID": "1_2_basic.html#함수",
    "href": "1_2_basic.html#함수",
    "title": "\n\n기초 문법\n",
    "section": "2.8. 함수",
    "text": "2.8. 함수\n\n함수(function)\n\n특정한 기능을 수행하도록 미리 만들어 놓고, 필요할 때마다 호출하여 사용하는 일련의 코드\nPython에서 제공하는 내장 함수와 사용자가 직접 정의하는 사용자 정의 함수가 있음\n\n\n\n\n함수를 사용하는 이유\n\n중복된 코드를 함수로 분리하면 코드의 양이 줄어들고 가독성이 향상됨\n코드가 간결해져 전체 기능을 더 쉽게 이해할 수 있음\n프로그램의 흐름을 파악하기 쉬워져 유지·보수가 편리함\n필요한 기능만 함수로 정의해두면, 다른 프로그램에서 쉽게 재사용할 수 있어 효율적임\n\n\n\n\n# enumerate() 함수 : for 문과 함께 사용하여 인덱스와 해당 값을 출력\nfor x, name in enumerate(['수박', '참외', '자두']):\n    print(x, name)\n\n0 수박\n1 참외\n2 자두\n\n\n\n# zip() 함수 : 두 리스트의 원소에 차례로 접근하여 짝을 지어 딕셔너리로 반환\nnum = [1, 2, 3]\nchar = ['A', 'B', 'C']\ndict(zip(num, char))\n\n{1: 'A', 2: 'B', 3: 'C'}\n\n\n\n# random() 함수 : 0.0과 1.0 사이의 임의의 실수 반환(0.0은 포함하나, 1.0은 포함하지 않음)\nimport random\nfor i in range(10):\n    x = random.random()\n    print(x)\n\n0.4791172832614309\n0.832109970499259\n0.15204512892843258\n0.7550887929410887\n0.9880572782008282\n0.33801286668402963\n0.6442643771665303\n0.414698401405464\n0.9043417166957826\n0.8595941445927859\n\n\n\n\n사용자 정의 함수\n\n인수(argument) : 호출된 함수에 전달할 값\n매개변수(parameter) : 호출된 함수에서 전달받은 값을 임시로 할당하는 변수\n반환값(return value) : 매개변수로부터 처리된 작업의 결과로, 호출한 함수로 값이 반환됨\n\n\n\n\ndef 함수명(매개변수1, 매개변수2, …):  　　문장  　　return 반환값\n\n\n\n함수명 작성 규칙\n\n변수명 작성 규칙과 동일함\n일반적으로 소문자로 입력\n작업을 나타내기 위해 동사와 명사를 함께 사용하는 경우가 많음 - (예) find_number\n외부에 공개하는 함수일 경우 줄임말을 사용하지 않고 짧고 명료한 이름으로 정함\n\n\n\n\n# 사용자 정의 함수 : 두 개의 수를 입력받아 큰 수를 반환하는 함수\ndef max(num1, num2):\n    if num1 &gt; num2:\n        return num1\n    else:\n        return num2\n\n#x = int(input('첫 번째 정수 입력 : '))\n#y = int(input('두 번째 정수 입력 : '))\n#print('큰 수 : ' max(x, y))\n\n\n\n람다 함수(lambda function)\n\n이름 없이 일시적으로 정의하여 사용할 수 있는 익명 함수\n간단한 함수를 짧게 작성할 수 있어, 다른 함수의 인수로 자주 사용됨\n\n\n\n\nlambda 매개변수들: 식\n\n\n\n# 사용자 정의 함수\ndef plus_five(x):\n    return x+5\n\nplus_five(20)\n\n25\n\n\n\n# 람다 함수\n(lambda x: x+5)(20)\n\n25\n\n\n\n# 람다 표현식을 인수로 사용\n# map() 함수 : iterable 객체의 모든 요소에 특정 함수를 적용한 결과를 반환\nresult = map(lambda x: x+5, [15, 25, 35])\nprint(list(result))\n\n[20, 30, 40]"
  },
  {
    "objectID": "2_2_pandas.html",
    "href": "2_2_pandas.html",
    "title": "\n\nPandas\n",
    "section": "",
    "text": "Pandas"
  },
  {
    "objectID": "2_2_pandas.html#데이터프레임",
    "href": "2_2_pandas.html#데이터프레임",
    "title": "\n\nPandas\n",
    "section": "4.1. 데이터프레임",
    "text": "4.1. 데이터프레임\n\nPandas 라이브러리\n\nNumPy 라이브러리를 기반으로 개발된 Python 데이터 분석 라이브러리\n다양한 형태의 데이터를 효율적으로 처리하고 탐색할 수 있음\n필터링, 정렬, 그룹화, 집계, 결측치 처리 등 다양한 분석 기능 제공\n\n\n\n\n시리즈(Series)\n\n1차원 데이터를 다루는 자료구조\n리스트와 달리 각 데이터에 인덱스를 지정할 수 있음\n\n\n\n\n데이터프레임(DataFrame)\n\n2차원 데이터를 다루는 자료구조\n행(row)과 열(column)로 이루어진 표(table) 형태의 구조를 가짐\n\n행(row) : 각 개별 데이터를 표현하며, 케이스(case)라고도 함\n열(column) : 속성을 표현하며, 변수(variable)라고도 함\n인덱스(index) : 각 개별 데이터를 특정할 수 있는 고유의 값으로, 행을 구분함\n\n열 단위로 서로 다른 자료형을 저장할 수 있으며, 각 열에는 동일한 자료형만 포함되어야 함"
  },
  {
    "objectID": "2_2_pandas.html#데이터프레임-생성",
    "href": "2_2_pandas.html#데이터프레임-생성",
    "title": "\n\nPandas\n",
    "section": "4.2. 데이터프레임 생성",
    "text": "4.2. 데이터프레임 생성\n\n데이터프레임 생성\n\nPandas 라이브러리의 DataFrame() 함수\n\n데이터를 직접 입력하는 방법으로, 일반적으로 딕셔너리를 많이 사용함\n\n키(key) : 열 이름\n값(value) : 각 열의 데이터\n\n\nPandas 라이브러리의 read_csv() 함수\n\n외부에 있는 csv 파일을 읽어 데이터프레임으로 생성함\n한글이 포함된 경우 encoding='euc-kr' 또는 encoding='cp949' 옵션을 지정해야 함\n[실습파일] exam.csv, music.csv, weather.csv, train.csv\n\n\n\n\n\n# Pandas 라이브러리 설치\n#!pip install pandas\n\n\n# Pandas 라이브러리 불러오기\nimport pandas as pd\n\n\n# 데이터프레임 생성1\ndf = pd.DataFrame({\n    'name': ['Jang', 'Yang', 'Oh'],\n    'dept': ['computer', 'english', 'math'],\n    'score': [100, 90, 50]})\ndf\n\n\n\n\n\n\n\n\nname\ndept\nscore\n\n\n\n\n0\nJang\ncomputer\n100\n\n\n1\nYang\nenglish\n90\n\n\n2\nOh\nmath\n50\n\n\n\n\n\n\n\n\n# 데이터프레임 생성2\ndf = pd.read_csv('./data/exam.csv')\ndf\n\n\n\n\n\n\n\n\nid\nnclass\nmath\nenglish\nscience\n\n\n\n\n0\n1\n1\n50\n98\n50\n\n\n1\n2\n1\n60\n97\n60\n\n\n2\n3\n1\n45\n86\n78\n\n\n3\n4\n1\n30\n98\n58\n\n\n4\n5\n2\n25\n80\n65\n\n\n5\n6\n2\n50\n89\n98\n\n\n6\n7\n2\n80\n90\n45\n\n\n7\n8\n2\n90\n78\n25\n\n\n8\n9\n3\n20\n98\n15\n\n\n9\n10\n3\n50\n98\n45\n\n\n10\n11\n3\n65\n65\n65\n\n\n11\n12\n3\n45\n85\n32\n\n\n12\n13\n4\n46\n98\n65\n\n\n13\n14\n4\n48\n87\n12\n\n\n14\n15\n4\n75\n56\n78\n\n\n15\n16\n4\n58\n98\n65\n\n\n16\n17\n5\n65\n68\n98\n\n\n17\n18\n5\n80\n78\n90\n\n\n18\n19\n5\n89\n68\n87\n\n\n19\n20\n5\n78\n83\n58"
  },
  {
    "objectID": "2_2_pandas.html#데이터프레임-확인",
    "href": "2_2_pandas.html#데이터프레임-확인",
    "title": "\n\nPandas\n",
    "section": "4.3. 데이터프레임 확인",
    "text": "4.3. 데이터프레임 확인\n\n데이터 분석 시 가장 먼저 데이터의 전반적인 구조를 파악해야 함\n\n\n\n# 데이터 불러오기\ndf = pd.read_csv(\"./data/music.csv\")\ndf\n\n\n\n\n\n\n\n\ntitle\nsinger\npersonnel\nsortation\nrelease_date\nagency\ngenre\ntype\n\n\n\n\n0\n좋은날\n아이유\n1\n솔로\n2010-12-09\n카카오엔터테인먼트\n발라드\nEP\n\n\n1\n내가제일잘나가\n2NE1\n4\n그룹\n2011-06-24\nYG엔터테인먼트\n댄스\n싱글\n\n\n2\n강남스타일\n싸이\n1\n솔로\n2012-07-15\nYG엔터테인먼트\n힙합\n정규\n\n\n3\n첫사랑니\nf(x)\n5\n그룹\n2013-07-29\nSM엔터테인먼트\n댄스\n정규\n\n\n4\n위아래\nEXID\n4\n그룹\n2014-08-27\n바나나컬쳐\n댄스\n싱글\n\n\n5\nAh-Choo\n러블리즈\n8\n그룹\n2015-10-01\n울림엔터테인먼트\n댄스\nEP\n\n\n6\n피땀눈물\n방탄소년단\n7\n그룹\n2016-10-10\n빅히트뮤직\nR&B\n정규\n\n\n7\n시간을달려서\n여자친구\n6\n그룹\n2016-01-25\n쏘스뮤직\n댄스\nEP\n\n\n8\n빨간맛\n레드벨벳\n5\n그룹\n2017-07-09\nSM엔터테인먼트\n댄스\nEP\n\n\n9\n에너제틱\n워너원\n11\n그룹\n2017-08-07\nYMC엔터테인먼트, 스톤뮤직엔터테인먼트\n댄스\nEP\n\n\n10\n뚜두뚜두\n블랙핑크\n4\n그룹\n2018-06-15\nYG엔터테인먼트\n댄스\nEP\n\n\n11\n달라달라\n있지\n5\n그룹\n2019-02-12\nJYP엔터테인먼트\n댄스\n싱글\n\n\n12\nDynamite\n방탄소년단\n7\n그룹\n2020-08-21\n빅히트뮤직\n댄스\n싱글\n\n\n\n\n\n\n\n\n# 변수 속성\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 13 entries, 0 to 12\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   title         13 non-null     object\n 1   singer        13 non-null     object\n 2   personnel     13 non-null     int64 \n 3   sortation     13 non-null     object\n 4   release_date  13 non-null     object\n 5   agency        13 non-null     object\n 6   genre         13 non-null     object\n 7   type          13 non-null     object\ndtypes: int64(1), object(7)\nmemory usage: 964.0+ bytes\n\n\n\n# 데이터 앞부분/뒷부분\ndf.head()\n# df.tail()\n\n\n\n\n\n\n\n\ntitle\nsinger\npersonnel\nsortation\nrelease_date\nagency\ngenre\ntype\n\n\n\n\n0\n좋은날\n아이유\n1\n솔로\n2010-12-09\n카카오엔터테인먼트\n발라드\nEP\n\n\n1\n내가제일잘나가\n2NE1\n4\n그룹\n2011-06-24\nYG엔터테인먼트\n댄스\n싱글\n\n\n2\n강남스타일\n싸이\n1\n솔로\n2012-07-15\nYG엔터테인먼트\n힙합\n정규\n\n\n3\n첫사랑니\nf(x)\n5\n그룹\n2013-07-29\nSM엔터테인먼트\n댄스\n정규\n\n\n4\n위아래\nEXID\n4\n그룹\n2014-08-27\n바나나컬쳐\n댄스\n싱글\n\n\n\n\n\n\n\n\n# 요약 통계량 : 수치형 변수\ndf.describe()\n\n\n\n\n\n\n\n\npersonnel\n\n\n\n\ncount\n13.000000\n\n\nmean\n5.230769\n\n\nstd\n2.712743\n\n\nmin\n1.000000\n\n\n25%\n4.000000\n\n\n50%\n5.000000\n\n\n75%\n7.000000\n\n\nmax\n11.000000\n\n\n\n\n\n\n\n\n# 요약 통계량 : 문자형 변수\ndf.describe(include='object')\n\n\n\n\n\n\n\n\ntitle\nsinger\nsortation\nrelease_date\nagency\ngenre\ntype\n\n\n\n\ncount\n13\n13\n13\n13\n13\n13\n13\n\n\nunique\n13\n12\n2\n13\n9\n4\n3\n\n\ntop\n좋은날\n방탄소년단\n그룹\n2010-12-09\nYG엔터테인먼트\n댄스\nEP\n\n\nfreq\n1\n2\n11\n1\n3\n10\n6\n\n\n\n\n\n\n\n\n# 인덱스\ndf.index\n\nRangeIndex(start=0, stop=13, step=1)\n\n\n\n# 열\ndf.columns\n\nIndex(['title', 'singer', 'personnel', 'sortation', 'release_date', 'agency',\n       'genre', 'type'],\n      dtype='object')\n\n\n\n# 각 열의 자료형\ndf.dtypes\n\ntitle           object\nsinger          object\npersonnel        int64\nsortation       object\nrelease_date    object\nagency          object\ngenre           object\ntype            object\ndtype: object\n\n\n\n# 정렬 : 오름차순(기본)\ndf.sort_values('release_date')\n\n\n\n\n\n\n\n\ntitle\nsinger\npersonnel\nsortation\nrelease_date\nagency\ngenre\ntype\n\n\n\n\n0\n좋은날\n아이유\n1\n솔로\n2010-12-09\n카카오엔터테인먼트\n발라드\nEP\n\n\n1\n내가제일잘나가\n2NE1\n4\n그룹\n2011-06-24\nYG엔터테인먼트\n댄스\n싱글\n\n\n2\n강남스타일\n싸이\n1\n솔로\n2012-07-15\nYG엔터테인먼트\n힙합\n정규\n\n\n3\n첫사랑니\nf(x)\n5\n그룹\n2013-07-29\nSM엔터테인먼트\n댄스\n정규\n\n\n4\n위아래\nEXID\n4\n그룹\n2014-08-27\n바나나컬쳐\n댄스\n싱글\n\n\n5\nAh-Choo\n러블리즈\n8\n그룹\n2015-10-01\n울림엔터테인먼트\n댄스\nEP\n\n\n7\n시간을달려서\n여자친구\n6\n그룹\n2016-01-25\n쏘스뮤직\n댄스\nEP\n\n\n6\n피땀눈물\n방탄소년단\n7\n그룹\n2016-10-10\n빅히트뮤직\nR&B\n정규\n\n\n8\n빨간맛\n레드벨벳\n5\n그룹\n2017-07-09\nSM엔터테인먼트\n댄스\nEP\n\n\n9\n에너제틱\n워너원\n11\n그룹\n2017-08-07\nYMC엔터테인먼트, 스톤뮤직엔터테인먼트\n댄스\nEP\n\n\n10\n뚜두뚜두\n블랙핑크\n4\n그룹\n2018-06-15\nYG엔터테인먼트\n댄스\nEP\n\n\n11\n달라달라\n있지\n5\n그룹\n2019-02-12\nJYP엔터테인먼트\n댄스\n싱글\n\n\n12\nDynamite\n방탄소년단\n7\n그룹\n2020-08-21\n빅히트뮤직\n댄스\n싱글\n\n\n\n\n\n\n\n\n# 빈도\ncnt = df['agency'].value_counts()\npd.DataFrame(cnt)\n\n\n\n\n\n\n\n\ncount\n\n\nagency\n\n\n\n\n\nYG엔터테인먼트\n3\n\n\nSM엔터테인먼트\n2\n\n\n빅히트뮤직\n2\n\n\n카카오엔터테인먼트\n1\n\n\n바나나컬쳐\n1\n\n\n울림엔터테인먼트\n1\n\n\n쏘스뮤직\n1\n\n\nYMC엔터테인먼트, 스톤뮤직엔터테인먼트\n1\n\n\nJYP엔터테인먼트\n1\n\n\n\n\n\n\n\n\n# 고유값\ndf['agency'].unique()\n\narray(['카카오엔터테인먼트', 'YG엔터테인먼트', 'SM엔터테인먼트', '바나나컬쳐', '울림엔터테인먼트', '빅히트뮤직',\n       '쏘스뮤직', 'YMC엔터테인먼트, 스톤뮤직엔터테인먼트', 'JYP엔터테인먼트'], dtype=object)"
  },
  {
    "objectID": "2_2_pandas.html#데이터프레임-선택",
    "href": "2_2_pandas.html#데이터프레임-선택",
    "title": "\n\nPandas\n",
    "section": "4.4. 데이터프레임 선택",
    "text": "4.4. 데이터프레임 선택\n\n\n\n4.4.1. 열 선택\n\n데이터프레임에서 특정 열을 선택할 때는 [] 안에 열 이름을 문자열로 입력함\n\n여러 개의 열을 선택하는 경우, 열 이름을 리스트로 전달함\n\n하나의 열만 선택하는 경우, (데이터프레임 이름).(열 이름) 형식으로도 접근할 수 있음\n\n\n\n# 열 선택1\ndf = pd.read_csv('./data/weather.csv', encoding='cp949')\ndf['평균기온']\n\n0     22.1\n1     21.5\n2     24.5\n3     25.6\n4     22.7\n5     19.7\n6     20.6\n7     21.2\n8     20.9\n9     20.9\n10    24.6\n11    24.6\n12    23.6\n13    21.5\n14    17.5\n15    20.3\n16    22.5\n17    23.3\n18    23.4\n19    25.2\n20    26.5\n21    25.9\n22    24.3\n23    22.6\n24    26.0\n25    26.5\n26    26.8\n27    26.9\n28    25.1\n29    22.3\nName: 평균기온, dtype: float64\n\n\n\n# 열 선택2\ndf[['최저기온', '최고기온']]\n\n\n\n\n\n\n\n\n최저기온\n최고기온\n\n\n\n\n0\n16.2\n28.6\n\n\n1\n17.1\n26.9\n\n\n2\n18.7\n32.6\n\n\n3\n20.3\n29.7\n\n\n4\n20.2\n27.0\n\n\n5\n16.7\n24.5\n\n\n6\n15.1\n25.1\n\n\n7\n16.2\n25.8\n\n\n8\n18.5\n24.5\n\n\n9\n17.2\n26.6\n\n\n10\n17.7\n32.7\n\n\n11\n18.9\n31.5\n\n\n12\n19.6\n29.2\n\n\n13\n17.7\n27.1\n\n\n14\n14.9\n20.1\n\n\n15\n17.6\n24.8\n\n\n16\n16.5\n28.1\n\n\n17\n22.0\n25.1\n\n\n18\n22.3\n25.1\n\n\n19\n22.0\n29.0\n\n\n20\n21.2\n32.6\n\n\n21\n21.9\n31.0\n\n\n22\n23.3\n26.4\n\n\n23\n20.6\n24.9\n\n\n24\n21.5\n30.5\n\n\n25\n24.8\n28.1\n\n\n26\n25.4\n28.1\n\n\n27\n25.7\n27.9\n\n\n28\n24.4\n26.1\n\n\n29\n21.2\n24.5\n\n\n\n\n\n\n\n\n\n\n4.4.2. 레이블이나 조건 표현으로 선택\n\n레이블(label)을 기반으로 행과 열을 선택할 때 loc[] 속성을 사용함\n\n열 이름을 이용하여 특정 열을 선택할 수 있음\n인덱스를 이용하여 특정 행을 선택할 수 있음\n조건식을 사용하여 특정 조건을 만족하는 행을 선택할 수 있음\n\n조건이 2개 이상인 경우, 각 조건을 ()로 묶고 논리 연산자(&, |, ~)를 사용함\n\n\n\n\n\n# 열 선택3\ndf.loc[:, ['날짜', '최고기온']]\n\n\n\n\n\n\n\n\n날짜\n최고기온\n\n\n\n\n0\n2022-06-01\n28.6\n\n\n1\n2022-06-02\n26.9\n\n\n2\n2022-06-03\n32.6\n\n\n3\n2022-06-04\n29.7\n\n\n4\n2022-06-05\n27.0\n\n\n5\n2022-06-06\n24.5\n\n\n6\n2022-06-07\n25.1\n\n\n7\n2022-06-08\n25.8\n\n\n8\n2022-06-09\n24.5\n\n\n9\n2022-06-10\n26.6\n\n\n10\n2022-06-11\n32.7\n\n\n11\n2022-06-12\n31.5\n\n\n12\n2022-06-13\n29.2\n\n\n13\n2022-06-14\n27.1\n\n\n14\n2022-06-15\n20.1\n\n\n15\n2022-06-16\n24.8\n\n\n16\n2022-06-17\n28.1\n\n\n17\n2022-06-18\n25.1\n\n\n18\n2022-06-19\n25.1\n\n\n19\n2022-06-20\n29.0\n\n\n20\n2022-06-21\n32.6\n\n\n21\n2022-06-22\n31.0\n\n\n22\n2022-06-23\n26.4\n\n\n23\n2022-06-24\n24.9\n\n\n24\n2022-06-25\n30.5\n\n\n25\n2022-06-26\n28.1\n\n\n26\n2022-06-27\n28.1\n\n\n27\n2022-06-28\n27.9\n\n\n28\n2022-06-29\n26.1\n\n\n29\n2022-06-30\n24.5\n\n\n\n\n\n\n\n\n# 행 선택1\ndf.loc[0:3]\n\n\n\n\n\n\n\n\n날짜\n평균기온\n최저기온\n최고기온\n\n\n\n\n0\n2022-06-01\n22.1\n16.2\n28.6\n\n\n1\n2022-06-02\n21.5\n17.1\n26.9\n\n\n2\n2022-06-03\n24.5\n18.7\n32.6\n\n\n3\n2022-06-04\n25.6\n20.3\n29.7\n\n\n\n\n\n\n\n\n# 행 선택2 : 날짜 데이터를 인덱스로 지정 후, 특정 날짜에 해당하는 행 선택\ndf.index = df['날짜']\ndf.loc['2022-06-05']\n\n날짜      2022-06-05\n평균기온          22.7\n최저기온          20.2\n최고기온          27.0\nName: 2022-06-05, dtype: object\n\n\n\n# 헹 선택3 : 조건을 만족하는 행 선택\nmask = df['평균기온']&gt;=25\ndf.loc[mask]\n\n\n\n\n\n\n\n\n날짜\n평균기온\n최저기온\n최고기온\n\n\n날짜\n\n\n\n\n\n\n\n\n2022-06-04\n2022-06-04\n25.6\n20.3\n29.7\n\n\n2022-06-20\n2022-06-20\n25.2\n22.0\n29.0\n\n\n2022-06-21\n2022-06-21\n26.5\n21.2\n32.6\n\n\n2022-06-22\n2022-06-22\n25.9\n21.9\n31.0\n\n\n2022-06-25\n2022-06-25\n26.0\n21.5\n30.5\n\n\n2022-06-26\n2022-06-26\n26.5\n24.8\n28.1\n\n\n2022-06-27\n2022-06-27\n26.8\n25.4\n28.1\n\n\n2022-06-28\n2022-06-28\n26.9\n25.7\n27.9\n\n\n2022-06-29\n2022-06-29\n25.1\n24.4\n26.1\n\n\n\n\n\n\n\n\n\n\n4.4.3. 부울 인덱싱\n\n조건식을 사용하면 각 행이 조건을 만족하는지 여부를 True 또는 False로 반환함\n그 결과인 부울(boolean)형 시리즈를 []에 전달하면 True에 해당하는 행만 선택할 수 있음\n조건이 2개 이상인 경우, 각 조건을 ()로 묶고 논리 연산자(&, |, ~)를 사용함\n\n\n\n# 부울 인덱싱1 : 조건을 만족하는 행 선택\nmask = df['최고기온']&gt;=30\ndf[mask]\n\n\n\n\n\n\n\n\n날짜\n평균기온\n최저기온\n최고기온\n\n\n날짜\n\n\n\n\n\n\n\n\n2022-06-03\n2022-06-03\n24.5\n18.7\n32.6\n\n\n2022-06-11\n2022-06-11\n24.6\n17.7\n32.7\n\n\n2022-06-12\n2022-06-12\n24.6\n18.9\n31.5\n\n\n2022-06-21\n2022-06-21\n26.5\n21.2\n32.6\n\n\n2022-06-22\n2022-06-22\n25.9\n21.9\n31.0\n\n\n2022-06-25\n2022-06-25\n26.0\n21.5\n30.5\n\n\n\n\n\n\n\n\n# 부울 인덱싱2 : 조건을 만족하는 행과 특정 열 선택\nmask = df['최고기온']&gt;=30\ndf[mask][['최저기온', '최고기온']]\n\n\n\n\n\n\n\n\n최저기온\n최고기온\n\n\n날짜\n\n\n\n\n\n\n2022-06-03\n18.7\n32.6\n\n\n2022-06-11\n17.7\n32.7\n\n\n2022-06-12\n18.9\n31.5\n\n\n2022-06-21\n21.2\n32.6\n\n\n2022-06-22\n21.9\n31.0\n\n\n2022-06-25\n21.5\n30.5\n\n\n\n\n\n\n\n\n# 불 인덱싱3 : 제일 더웠던 날 선택\nmask = df['최고기온']==df['최고기온'].max()\ndf[mask]\n\n\n\n\n\n\n\n\n날짜\n평균기온\n최저기온\n최고기온\n\n\n날짜\n\n\n\n\n\n\n\n\n2022-06-11\n2022-06-11\n24.6\n17.7\n32.7\n\n\n\n\n\n\n\n\n# [Note] 특정 조건을 만족하는 데이터 선택\ndf.query('최고기온-최저기온&gt;=10')\n\n\n\n\n\n\n\n\n날짜\n평균기온\n최저기온\n최고기온\n\n\n날짜\n\n\n\n\n\n\n\n\n2022-06-01\n2022-06-01\n22.1\n16.2\n28.6\n\n\n2022-06-03\n2022-06-03\n24.5\n18.7\n32.6\n\n\n2022-06-07\n2022-06-07\n20.6\n15.1\n25.1\n\n\n2022-06-11\n2022-06-11\n24.6\n17.7\n32.7\n\n\n2022-06-12\n2022-06-12\n24.6\n18.9\n31.5\n\n\n2022-06-17\n2022-06-17\n22.5\n16.5\n28.1\n\n\n2022-06-21\n2022-06-21\n26.5\n21.2\n32.6"
  },
  {
    "objectID": "2_2_pandas.html#데이터-가공-및-그룹핑",
    "href": "2_2_pandas.html#데이터-가공-및-그룹핑",
    "title": "\n\nPandas\n",
    "section": "4.5. 데이터 가공 및 그룹핑",
    "text": "4.5. 데이터 가공 및 그룹핑\n\n4.5.1. 데이터 가공\n\ndrop() 메소드를 이용하여 특정 행 또는 열을 삭제할 수 있음\n\n행 삭제(axis=0) : index 인자에 삭제할 행에 대한 인덱스를 지정함\n\n특정 조건을 만족하는 행의 위치에 대한 인덱스를 추출하려면 index 속성을 이용함\n\n열 삭제(axis=1) : columns 인자에 삭제할 열 이름을 리스트 형태로 지정함\n원본 데이터를 직접 수정하려면 inplace=True 옵션을 지정함\n\n\n\n\n# 데이터 불러오기\ndf = pd.read_csv(\"./data/music.csv\")\ndf\n\n\n\n\n\n\n\n\ntitle\nsinger\npersonnel\nsortation\nrelease_date\nagency\ngenre\ntype\n\n\n\n\n0\n좋은날\n아이유\n1\n솔로\n2010-12-09\n카카오엔터테인먼트\n발라드\nEP\n\n\n1\n내가제일잘나가\n2NE1\n4\n그룹\n2011-06-24\nYG엔터테인먼트\n댄스\n싱글\n\n\n2\n강남스타일\n싸이\n1\n솔로\n2012-07-15\nYG엔터테인먼트\n힙합\n정규\n\n\n3\n첫사랑니\nf(x)\n5\n그룹\n2013-07-29\nSM엔터테인먼트\n댄스\n정규\n\n\n4\n위아래\nEXID\n4\n그룹\n2014-08-27\n바나나컬쳐\n댄스\n싱글\n\n\n5\nAh-Choo\n러블리즈\n8\n그룹\n2015-10-01\n울림엔터테인먼트\n댄스\nEP\n\n\n6\n피땀눈물\n방탄소년단\n7\n그룹\n2016-10-10\n빅히트뮤직\nR&B\n정규\n\n\n7\n시간을달려서\n여자친구\n6\n그룹\n2016-01-25\n쏘스뮤직\n댄스\nEP\n\n\n8\n빨간맛\n레드벨벳\n5\n그룹\n2017-07-09\nSM엔터테인먼트\n댄스\nEP\n\n\n9\n에너제틱\n워너원\n11\n그룹\n2017-08-07\nYMC엔터테인먼트, 스톤뮤직엔터테인먼트\n댄스\nEP\n\n\n10\n뚜두뚜두\n블랙핑크\n4\n그룹\n2018-06-15\nYG엔터테인먼트\n댄스\nEP\n\n\n11\n달라달라\n있지\n5\n그룹\n2019-02-12\nJYP엔터테인먼트\n댄스\n싱글\n\n\n12\nDynamite\n방탄소년단\n7\n그룹\n2020-08-21\n빅히트뮤직\n댄스\n싱글\n\n\n\n\n\n\n\n\n# 여러 개의 열 삭제\ndf.drop(columns = ['sortation', 'agency'], inplace=True)\ndf.columns\n\nIndex(['title', 'singer', 'personnel', 'release_date', 'genre', 'type'], dtype='object')\n\n\n\n# 열 이름 변경\ndf.columns = ['노래제목', '가수', '인원수', '발매일', '장르', '유형']\ndf.head()\n\n\n\n\n\n\n\n\n노래제목\n가수\n인원수\n발매일\n장르\n유형\n\n\n\n\n0\n좋은날\n아이유\n1\n2010-12-09\n발라드\nEP\n\n\n1\n내가제일잘나가\n2NE1\n4\n2011-06-24\n댄스\n싱글\n\n\n2\n강남스타일\n싸이\n1\n2012-07-15\n힙합\n정규\n\n\n3\n첫사랑니\nf(x)\n5\n2013-07-29\n댄스\n정규\n\n\n4\n위아래\nEXID\n4\n2014-08-27\n댄스\n싱글\n\n\n\n\n\n\n\n\n# 발매일 변수를 datetime 형식으로 변환\ndf['발매일'] = pd.to_datetime(df['발매일'])\ndf.dtypes\n\n노래제목            object\n가수              object\n인원수              int64\n발매일     datetime64[ns]\n장르              object\n유형              object\ndtype: object\n\n\n\n# 새로운 열 생성\ndf['연도'] = df['발매일'].dt.year\ndf['월'] = df['발매일'].dt.month\ndf['일'] = df['발매일'].dt.day\ndf.head()\n\n\n\n\n\n\n\n\n노래제목\n가수\n인원수\n발매일\n장르\n유형\n연도\n월\n일\n\n\n\n\n0\n좋은날\n아이유\n1\n2010-12-09\n발라드\nEP\n2010\n12\n9\n\n\n1\n내가제일잘나가\n2NE1\n4\n2011-06-24\n댄스\n싱글\n2011\n6\n24\n\n\n2\n강남스타일\n싸이\n1\n2012-07-15\n힙합\n정규\n2012\n7\n15\n\n\n3\n첫사랑니\nf(x)\n5\n2013-07-29\n댄스\n정규\n2013\n7\n29\n\n\n4\n위아래\nEXID\n4\n2014-08-27\n댄스\n싱글\n2014\n8\n27\n\n\n\n\n\n\n\n\n\n\n4.5.2. 데이터 그룹핑\n\ngroupby() 메소드를 이용하여 특정 열을 기준으로 데이터를 그룹화할 수 있음\n통계량을 산출하는 메소드 mean(), std(), var(), max(), min(), mode() 등과 함께 사용됨\n\n\n\n# 데이터 그룹핑1\nnewdata = df.groupby(['장르']).count()\npd.DataFrame(newdata['노래제목'])\n# df.value_counts('장르')\n\n\n\n\n\n\n\n\n노래제목\n\n\n장르\n\n\n\n\n\nR&B\n1\n\n\n댄스\n10\n\n\n발라드\n1\n\n\n힙합\n1\n\n\n\n\n\n\n\n\n# 데이터 그룹핑2\nnewdata = df.groupby(['장르'])['인원수'].mean()\npd.DataFrame(newdata)\n\n\n\n\n\n\n\n\n인원수\n\n\n장르\n\n\n\n\n\nR&B\n7.0\n\n\n댄스\n5.9\n\n\n발라드\n1.0\n\n\n힙합\n1.0"
  },
  {
    "objectID": "2_2_pandas.html#결측-데이터-처리",
    "href": "2_2_pandas.html#결측-데이터-처리",
    "title": "\n\nPandas\n",
    "section": "4.6. 결측 데이터 처리",
    "text": "4.6. 결측 데이터 처리\n\n결측 데이터(missing value)\n\nPandas는 누락된 데이터를 NaN(Not a Number)로 표기하며, 연산 시 자동으로 제외됨\nisna(), isnull() 메소드를 이용하면 결측값을 확인할 수 있음\n\n\n\n\n결측 데이터 처리\n\n가장 간단한 방법은 dropna() 메소드를 이용하여 결측값이 포함된 행이나 열을 삭제하는 것임\n\naxis=0이면 행, axis=1이면 열을 삭제함\n\nfillna() 메소드를 이용하여 결측값을 최빈값이나 평균, 중앙값으로 대체할 수도 있음\n\n\n\n\n# 데이터 불러오기\ndf = pd.read_csv(\"./data/train.csv\")\ndf\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n887\n0\n2\nMontvila, Rev. Juozas\nmale\n27.0\n0\n0\n211536\n13.0000\nNaN\nS\n\n\n887\n888\n1\n1\nGraham, Miss. Margaret Edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n\n\n888\n889\n0\n3\nJohnston, Miss. Catherine Helen \"Carrie\"\nfemale\nNaN\n1\n2\nW./C. 6607\n23.4500\nNaN\nS\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n\n\n890\n891\n0\n3\nDooley, Mr. Patrick\nmale\n32.0\n0\n0\n370376\n7.7500\nNaN\nQ\n\n\n\n\n891 rows × 12 columns\n\n\n\n\n# 결측값 확인\ndf[df['Embarked'].isna()]\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n61\n62\n1\n1\nIcard, Miss. Amelie\nfemale\n38.0\n0\n0\n113572\n80.0\nB28\nNaN\n\n\n829\n830\n1\n1\nStone, Mrs. George Nelson (Martha Evelyn)\nfemale\n62.0\n0\n0\n113572\n80.0\nB28\nNaN\n\n\n\n\n\n\n\n\n# 각 열별 결측값 개수 확인\n# 부울형은 산술 연산 시 True는 1, False는 0으로 계산되므로\n# isna() 결과에 sum()을 적용하면 결측값 개수가 계산됨\ndf.isna().sum()\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\n\n\n# 결측값이 포함된 열 삭제\ndf.drop('Cabin', axis=1, inplace=True)\ndf.columns\n\nIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Embarked'],\n      dtype='object')\n\n\n\n# 결측값이 포함된 행 삭제\ndf.dropna(axis=0)\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n885\n886\n0\n3\nRice, Mrs. William (Margaret Norton)\nfemale\n39.0\n0\n5\n382652\n29.1250\nQ\n\n\n886\n887\n0\n2\nMontvila, Rev. Juozas\nmale\n27.0\n0\n0\n211536\n13.0000\nS\n\n\n887\n888\n1\n1\nGraham, Miss. Margaret Edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nS\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC\n\n\n890\n891\n0\n3\nDooley, Mr. Patrick\nmale\n32.0\n0\n0\n370376\n7.7500\nQ\n\n\n\n\n712 rows × 11 columns\n\n\n\n\n# 결측값을 최빈값으로 대체\nembarked_mode = df['Embarked'].mode()[0]\ndf['Embarked'] = df['Embarked'].fillna(embarked_mode)\ndf.isna().sum()\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nEmbarked         0\ndtype: int64\n\n\n\n# 결측값을 평균으로 대체\nage_mean = df['Age'].mean()\ndf['Age'] = df['Age'].fillna(age_mean)\ndf.isna().sum()\n\nPassengerId    0\nSurvived       0\nPclass         0\nName           0\nSex            0\nAge            0\nSibSp          0\nParch          0\nTicket         0\nFare           0\nEmbarked       0\ndtype: int64"
  },
  {
    "objectID": "2_4_seaborn.html",
    "href": "2_4_seaborn.html",
    "title": "\n\nSeaborn\n",
    "section": "",
    "text": "Seaborn"
  },
  {
    "objectID": "2_4_seaborn.html#seaborn",
    "href": "2_4_seaborn.html#seaborn",
    "title": "\n\nSeaborn\n",
    "section": "6.1. Seaborn",
    "text": "6.1. Seaborn\n\nSeaborn\n\nMatplotlib 라이브러리를 기반으로 개발된 고급 통계 데이터 시각화 라이브러리\n다양한 테마와 통계 그래프를 지원하며, 시각적으로 세련된 그래프를 쉽게 생성할 수 있음\nMatplotlib 라이브러리에 의존하므로, 사용 시 함께 불러와야 함\n\n\n\n\n\n\n\n\n\n\n주요 특징\n시각화 단계\n\n\n\n\n- 뛰어난 시각화 효과 - 간결한 구문 제공 - Pandas 데이터프레임에 최적화 - 쉬운 데이터프레임 집계 및 그래프 요약\n- 데이터 준비 - 배경 설정 - 시각화 - 개별 그래프 상세 설정\n\n\n\n\n\n\n[데이터] 공공데이터포털에서 제공하는 2020년 국민건강보험공단 건강검진 정보\n\ngender, height, weight, waist, smoking, drinking 등 18개 변수\n[실습파일] 05_data1.csv"
  },
  {
    "objectID": "2_4_seaborn.html#막대-그래프",
    "href": "2_4_seaborn.html#막대-그래프",
    "title": "\n\nSeaborn\n",
    "section": "6.2. 막대 그래프",
    "text": "6.2. 막대 그래프\n\n\n# Seaborn 라이브러리 설치\n#!pip install seaborn\n\n\n# Seaborn 라이브러리 불러오기\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport numpy as np\nimport pandas as pd\n\n\n# 데이터 불러오기\ndata = pd.read_csv('./data/05_data1.csv')\ndata.head()\n\n\n\n\n\n\n\n\nno\ncity_code\ngender\nage_code\nheight\nweight\nwaist\nsystolic\ndiastolic\nblood_sugar\ncholesterol\ntriglycerides\nHDL\nLDL\nhemoglobin\nserum\nsmoking\ndrinking\n\n\n\n\n0\n1\n36\n1\n9\n165\n60\n72.1\n127\n79\n90\n188\n58\n58.0\n118\n15.0\n1.1\n1\n0\n\n\n1\n5\n41\n2\n12\n155\n50\n75.2\n144\n89\n110\n220\n171\n53.0\n133\n12.4\n0.7\n1\n0\n\n\n2\n6\n27\n1\n9\n185\n85\n94.0\n114\n72\n86\n234\n183\n50.0\n147\n16.4\n1.1\n3\n1\n\n\n3\n7\n44\n1\n9\n165\n80\n93.0\n112\n73\n250\n119\n265\n26.0\n40\n15.7\n0.7\n3\n1\n\n\n4\n9\n41\n2\n17\n150\n50\n82.0\n136\n65\n104\n177\n61\n63.0\n101\n13.3\n0.7\n1\n0\n\n\n\n\n\n\n\n\n# 데이터 전처리 : 라벨 매핑(label mapping)\n# replace() 함수는 명시되지 않은 값을 그대로 유지하지만,\n# map() 함수는 명시되지 않은 값을 NaN으로 처리함\ndata6 = data.copy()\ndata6 = data6.loc[:, ['gender', 'height', 'weight', 'waist', 'drinking', 'smoking']]\ndata6['gender'] = data['gender'].replace({1: 'M', 2: 'F'})\ndata6['drinking'] = data['drinking'].replace({0: 'Non-drinking', 1: 'Drinking'})\ndata6['smoking'] = data['smoking'].replace({1: 'Non-smoking', 2: 'Quit-smoking', 3: 'Smoking'})\ndata6.head()\n\n\n\n\n\n\n\n\ngender\nheight\nweight\nwaist\ndrinking\nsmoking\n\n\n\n\n0\nM\n165\n60\n72.1\nNon-drinking\nNon-smoking\n\n\n1\nF\n155\n50\n75.2\nNon-drinking\nNon-smoking\n\n\n2\nM\n185\n85\n94.0\nDrinking\nSmoking\n\n\n3\nM\n165\n80\n93.0\nDrinking\nSmoking\n\n\n4\nF\n150\n50\n82.0\nNon-drinking\nNon-smoking\n\n\n\n\n\n\n\n\n# 데이터 집계 :성별 음주 여부별 빈도\ndrinking = data6.groupby(['gender', 'drinking'])['drinking'].count()\ndrinking = drinking.to_frame(name='count')\ndrinking = drinking.reset_index()\ndrinking\n\n\n\n\n\n\n\n\ngender\ndrinking\ncount\n\n\n\n\n0\nF\nDrinking\n611\n\n\n1\nF\nNon-drinking\n888\n\n\n2\nM\nDrinking\n1086\n\n\n3\nM\nNon-drinking\n415\n\n\n\n\n\n\n\n\n# 데이터 집계 :성별 흡연 상태별 빈도\nsmoking = data6.groupby(['gender', 'smoking'])['smoking'].count()\nsmoking = smoking.to_frame(name='count')\nsmoking = smoking.reset_index()\nsmoking\n\n\n\n\n\n\n\n\ngender\nsmoking\ncount\n\n\n\n\n0\nF\nNon-smoking\n1422\n\n\n1\nF\nQuit-smoking\n45\n\n\n2\nF\nSmoking\n32\n\n\n3\nM\nNon-smoking\n502\n\n\n4\nM\nQuit-smoking\n519\n\n\n5\nM\nSmoking\n480\n\n\n\n\n\n\n\n\n# 막대 그래프 : 성별에 따른 음주 여부, 흡연 상태 분포\nfig = plt.figure(figsize=(8, 4))\narea1 = fig.add_subplot(1, 2, 1)\narea2 = fig.add_subplot(1, 2, 2)\n\nax1 = sns.barplot(x='gender', y='count', hue='drinking', data=drinking, ax=area1)\nax2 = sns.barplot(x='gender', y='count', hue='smoking', data=smoking, ax=area2)\n\nfig.suptitle('2020 Health Check Drinking & Smoking Type by Gender', fontweight='bold')\narea1.set_title('Drinking Type')\narea2.set_title('Smoking Type')\nplt.tight_layout(rect=[0, 0, 1, 0.99])\nplt.show()\n\n\n\n\n\n\n\n\n\n# 데이터 집계 :성별 흡연 상태별 평균 몸무게\nmean_weight = data6.groupby(['gender', 'smoking'])['weight'].mean()\nmean_weight = mean_weight.to_frame(name='mean')\nmean_weight = mean_weight.reset_index()\nmean_weight\n\n\n\n\n\n\n\n\ngender\nsmoking\nmean\n\n\n\n\n0\nF\nNon-smoking\n55.706751\n\n\n1\nF\nQuit-smoking\n55.555556\n\n\n2\nF\nSmoking\n59.843750\n\n\n3\nM\nNon-smoking\n68.914343\n\n\n4\nM\nQuit-smoking\n70.337187\n\n\n5\nM\nSmoking\n69.052083\n\n\n\n\n\n\n\n\n# 막대 그래프 : 성별과 흡연 상태에 따른 평균 몸무게\nplt.figure(figsize=(5, 3))\nsns.barplot(x='gender', y='mean', hue='smoking', data=mean_weight)\nplt.show()"
  },
  {
    "objectID": "2_4_seaborn.html#히스토그램",
    "href": "2_4_seaborn.html#히스토그램",
    "title": "\n\nSeaborn\n",
    "section": "6.3. 히스토그램",
    "text": "6.3. 히스토그램\n\n\n# 데이터 전처리 : 성별에 따라 데이터 분리\nmaledata = data6.copy()\nmaledata = maledata.loc[maledata['gender']=='M',:]\n\nfemaledata = data6.copy()\nfemaledata = femaledata.loc[femaledata['gender']=='F',:]\n\n\n# 히스토그램 : 성별에 따른 몸무게 분포\nplt.figure(figsize=(5, 3))\nplt.title('Distribution of Weight')\nsns.histplot(maledata['weight'], bins=8, alpha=0.5, label='Male')\nsns.histplot(femaledata['weight'], bins=8, alpha=0.5, label='Female', color='r')\nplt.xlim(20, 130)\nplt.xlabel('weight')\nplt.ylabel('count')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# 히스토그램 & 커널 밀도 추정(KDE) : 성별에 따른 허리둘레 분포\nplt.figure(figsize=(5, 3))\nplt.title('Distribution of Waist with KDE')\nsns.histplot(maledata['waist'], bins=7, alpha=0.5, label='Male', kde=True)\nsns.histplot(femaledata['waist'], bins=7, alpha=0.5, label='Female', color='r', kde=True)\nplt.xlim(40,130)\nplt.xlabel('waist')\nplt.ylabel('count')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "2_4_seaborn.html#상자수염-그래프",
    "href": "2_4_seaborn.html#상자수염-그래프",
    "title": "\n\nSeaborn\n",
    "section": "6.4. 상자수염 그래프",
    "text": "6.4. 상자수염 그래프\n\n\n# 상자수염 그래프 : 성별 및 음주 여부에 따른 몸무게 분포\nplt.figure(figsize=(8, 4))\nplt.title('Weight By Gender and Drinking')\nsns.boxplot(x='gender', y='weight', hue='drinking', width=0.7, gap = 0.1, data=data6)\nplt.show()\n\n\n\n\n\n\n\n\n\n# 상자수염 그래프 : 성별 및 흡연 상태에 따른 몸무게 분포\nplt.figure(figsize=(8, 6))\nplt.title('Weight By Gender and Smoking')\nsns.boxplot(x='weight', y='gender', hue='smoking', width=0.7, gap=0.1, data=data6, orient='h')\nplt.show()"
  },
  {
    "objectID": "2_4_seaborn.html#카운트-플롯count-plot",
    "href": "2_4_seaborn.html#카운트-플롯count-plot",
    "title": "\n\nSeaborn\n",
    "section": "6.5. 카운트 플롯(count plot)",
    "text": "6.5. 카운트 플롯(count plot)\n\n범주형 변수의 각 항목별 빈도를 막대 그래프로 표현함\n데이터의 범주별 분포를 직관적으로 파악할 수 있음\n\n\n\n# 카운트 플롯1 : 음주 여부에 따른 성별 분포\nplt.figure(figsize=(5, 3))\nplt.title('Gender and Drinking')\nsns.countplot(x='drinking', hue='gender', data=data6)\nplt.xlabel('')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 카운트 플롯2 : 흡연 상태에 따른 성별 분포\nplt.figure(figsize=(5, 3))\nplt.title('Gender and Smoking')\nsns.countplot(y='smoking', hue='gender',\n              data=data6, order=['Smoking', 'Quit-smoking', 'Non-smoking'])\nplt.ylabel('')\nplt.show()"
  },
  {
    "objectID": "2_4_seaborn.html#히트맵heatmap",
    "href": "2_4_seaborn.html#히트맵heatmap",
    "title": "\n\nSeaborn\n",
    "section": "6.5. 히트맵(heatmap)",
    "text": "6.5. 히트맵(heatmap)\n\n행과 열로 이루어진 2차원 행렬 데이터를 색상으로 시각화함\n두 범주형 변수 간의 관계나 상관관계를 나타낼 때 사용\n색상의 강도를 통해 값의 크기를 비교할 수 있음\n예 : 상관행렬, 교차표 등\n\n\n\n# 데이터 전처리 : 8개 건강 지표 선택\ndata8 = data.copy()\ndata8 = data8.loc[:, ['height', 'weight', 'waist',\n                      'systolic', 'diastolic', 'cholesterol', 'HDL', 'LDL']]\n\n\n# 히트맵 : 8개의 건강 지표 간 상관관계\n# 상관계수는 -1에서 +1 사이의 값을 가지므로,\n# vmin=-1, vmax=1 옵션 설정으로 색상 범위의 균형을 맞춤\ncorrelation_data8 = data8.corr()\nupp_mat = np.triu(correlation_data8)\n\nplt.figure(figsize=(8, 6))\nplt.title('Correlation Heatmap')\nsns.heatmap(correlation_data8, annot=True, mask=upp_mat, cmap='seismic', vmin=-1, vmax=1)\nplt.xticks(rotation=45)\nplt.show()"
  },
  {
    "objectID": "2_4_seaborn.html#기타-시각화",
    "href": "2_4_seaborn.html#기타-시각화",
    "title": "\n\nSeaborn\n",
    "section": "6.7. 기타 시각화",
    "text": "6.7. 기타 시각화\n\n\n\n\n\n\n\n시각화 유형\n설명\n\n\n\n\n스트립 플롯 (strip plot)\n- 데이터 분포를 요약하여 간략히 띠 형태로 시각화함 - 일반적으로 x축에는 범주형 변수, y축에는 수치형 변수를 지정함 - 주로 데이터 수가 적을 때 사용됨\n\n\n스웜 플롯 (swarm plot)\n- 스트립 플롯과 유사하지만, 점들을 겹치지 않도록 자동으로 위치를 조정함 - 분포를 보여줄 때 효과적이나, 데이터 수가 많을 때에는 개수를 대략적으로 파악하기 어려움\n\n\n바이올린 플롯 (violin plot)\n- 커널 밀도 추정(KDE)을 이용하여 데이터의 분포를 시각화함 - 상자수염 그래프와 KDE를 결합한 형태로 중앙값, 사분위수, 전체 분포를 동시에 보여줌 - 분포를 비교하는 데 효과적이나, 데이터 수가 적을 경우 왜곡된 해석 가능성 있음\n\n\n\n\n\n# 스트립 플롯 : 키와 몸무게, 성별의 관계\nplt.figure(figsize=(8, 4))\nplt.title('Height vs Weight by Gender - Strip Plot')\nsns.stripplot(x='height', y='weight', hue='gender', alpha=0.5, palette='dark', data=femaledata)\nsns.stripplot(x='height', y='weight', hue='gender', alpha=0.5, palette='Set1', data=maledata)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# 데이터 전처리 : 남성, 여성 각각 100개 데이터 선택\nmaledata100 = maledata.head(100)\nfemaledata100 = femaledata.head(100)\n\n\n# 스웜 플롯 : 키와 몸무게, 성별의 관계\nplt.figure(figsize=(8, 4))\nplt.title('Height vs Weight by Gender - Swarm Plot')\nsns.stripplot(x='height', y='weight', hue='gender', alpha=0.5, palette='dark', data=femaledata100)\nsns.stripplot(x='height', y='weight', hue='gender', alpha=0.5, palette='Set1', data=maledata100)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# 바이올린 플롯1 : 성별 및 음주 여부별 몸무게(120 미만) 분포\nplt.figure(figsize=(5, 3))\nplt.title('Weight By Gender and Drinking (Under 120kg)')\nsns.violinplot(x='gender', y='weight', hue='drinking', gap=0.1, data=data6[data6.weight&lt;120])\nplt.show()\n\n\n\n\n\n\n\n\n\n# 바이올린 플롯2 : 성별 및 음주 여부별 허리둘레(150 미만) 분포\nplt.figure(figsize=(5, 5))\nplt.title('Waist By Gender and Drinking (Under 150cm)')\nsns.violinplot(y='gender', x='waist', hue='drinking', gap=0.1, data=data6[data6.waist&lt;150])\nplt.show()"
  },
  {
    "objectID": "3_2_regression.html",
    "href": "3_2_regression.html",
    "title": "\n\n지도학습 : 회귀\n",
    "section": "",
    "text": "지도학습 : 회귀"
  },
  {
    "objectID": "3_2_regression.html#상관분석",
    "href": "3_2_regression.html#상관분석",
    "title": "\n\n지도학습 : 회귀\n",
    "section": "8.1. 상관분석",
    "text": "8.1. 상관분석\n\n8.1.1. 상관계수\n\n상관분석(correlation analysis)\n\n두 수치형 변수 간 선형적인 관계(linear relationship)를 파악하는 통계 기법\n상관계수(correlation coefficient)\n\n두 변수 간 상관관계를 수치로 나타내어 정량화한 지표\n상관계수의 절대값은 선형성의 강도를, 부호는 선형성의 방향성을 나타냄\n변수의 측정 단위의 영향을 받지 않음\n\n\n\n\n\n상관계수의 성질\n\n상관계수 r은 항상 -1에서 +1 사이의 값을 가짐\n절대값이 1에 가까울수록 강한 상관관계를 의미함\nr&gt;0이면 양의 상관관계, r&lt;0이면 음의 상관관계, r=0이면 상관관계가 없음을 나타냄\n\n양의 상관관계 : 한 변수가 증가할 때 다른 변수도 증가\n음의 상관관계 : 한 변수가 증가할 때 다른 변수는 감소\n상관관계 없음 : 한 변수가 증가할 때 다른 변수는 영향을 받지 않음\n\n\n\n\n\n\n\n\n8.1.2. (실습) 행복지수 데이터 분석\n\n[데이터] 캐글에서 제공하는 전세계 행복지수 데이터\n\n1인당 GDP, 사회적 지지 정도, 건강한 기대수명, 인생 선택의 자유, 기부\n[실습파일] 2020.csv, 2021.csv\n\n\n\n\n행복지수와 관련된 요인은 무엇일까?\n\n\n\n## (1) 데이터 확인 및 전처리\n\n\n# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# 데이터 불러오기\ndf2020 = pd.read_csv('./data/2020.csv', index_col=0)\ndf2021 = pd.read_csv('./data/2021.csv', index_col=0)\n\n\n# 열 정보\ndf2020.dtypes\n\nCountry name                     object\nHappiness score                 float64\nupperwhisker                    float64\nlowerwhisker                    float64\nGDP per capita                  float64\nSocial support                  float64\nHealthy life expectancy         float64\nFreedom to make life choices    float64\nGenerosity                      float64\nDystopia                        float64\ndtype: object\n\n\n\n# 2020년 데이터 확인\ndf2020.head()\n\n\n\n\n\n\n\n\nCountry name\nHappiness score\nupperwhisker\nlowerwhisker\nGDP per capita\nSocial support\nHealthy life expectancy\nFreedom to make life choices\nGenerosity\nDystopia\n\n\nRank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nFinland\n7.8087\n7.869766\n7.747634\n10.639267\n0.954330\n71.900825\n0.949172\n-0.059482\n2.762835\n\n\n2\nDenmark\n7.6456\n7.711245\n7.579955\n10.774001\n0.955991\n72.402504\n0.951444\n0.066202\n2.432741\n\n\n3\nSwitzerland\n7.5599\n7.628528\n7.491272\n10.979933\n0.942847\n74.102448\n0.921337\n0.105911\n2.350267\n\n\n4\nIceland\n7.5045\n7.621347\n7.387653\n10.772559\n0.974670\n73.000000\n0.948892\n0.246944\n2.460688\n\n\n5\nNorway\n7.4880\n7.556281\n7.419719\n11.087804\n0.952487\n73.200783\n0.955750\n0.134533\n2.168266\n\n\n\n\n\n\n\n\n# 2021년 데이터 확인\ndf2021.head()\n\n\n\n\n\n\n\n\nCountry name\nHappiness score\nupperwhisker\nlowerwhisker\nGDP per capita\nSocial support\nHealthy life expectancy\nFreedom to make life choices\nGenerosity\nDystopia\n\n\nRank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nFinland\n7.842\n7.904\n7.780\n10.775\n0.954\n72.0\n0.949\n-0.098\n3.253\n\n\n2\nDenmark\n7.620\n7.687\n7.552\n10.933\n0.954\n72.7\n0.946\n0.030\n2.868\n\n\n3\nSwitzerland\n7.571\n7.643\n7.500\n11.117\n0.942\n74.4\n0.919\n0.025\n2.839\n\n\n4\nIceland\n7.554\n7.670\n7.438\n10.878\n0.983\n73.0\n0.955\n0.160\n2.967\n\n\n5\nNetherlands\n7.464\n7.518\n7.410\n10.932\n0.942\n72.4\n0.913\n0.175\n2.798\n\n\n\n\n\n\n\n\n# 데이터 전처리 : 열 삭제\ndf2020.drop(['upperwhisker', 'lowerwhisker', 'Dystopia'], axis=1, inplace=True)\ndf2021.drop(['upperwhisker', 'lowerwhisker', 'Dystopia'], axis=1, inplace=True)\n\n\n# 열 이름 변경 : 공백을 _으로 대체\n#df2020.columns = df2020.columns.str.replace(' ','._')\n#df2021.columns = df2021.columns.str.replace(' ','_')\n\n\n# 데이터 전처리 : 열 이름 변경\ndf2020.columns = ['Country', 'Score', 'GDP_per_capita', 'Social_support', 'Life_expectancy', 'Freedom', 'Generosity']\ndf2021.columns = ['Country', 'Score', 'GDP_per_capita', 'Social_support', 'Life_expectancy', 'Freedom', 'Generosity']\n\n\n\n## (2) 데이터 분석 및 시각화\n## (2-1) 행복 점수와 기능의 상관관계\n##       한 국가의 행복지수와 경제적(GDP), 법적 상태(Freedom)는 상관관계가 있는가?\n\n\n# 2020년 데이터 전처리\ndf1 = df2020.copy()\ndf1.drop(['Social_support', 'Life_expectancy', 'Generosity'], axis=1, inplace=True)\ndf1.head()\n\n\n\n\n\n\n\n\nCountry\nScore\nGDP_per_capita\nFreedom\n\n\nRank\n\n\n\n\n\n\n\n\n1\nFinland\n7.8087\n10.639267\n0.949172\n\n\n2\nDenmark\n7.6456\n10.774001\n0.951444\n\n\n3\nSwitzerland\n7.5599\n10.979933\n0.921337\n\n\n4\nIceland\n7.5045\n10.772559\n0.948892\n\n\n5\nNorway\n7.4880\n11.087804\n0.955750\n\n\n\n\n\n\n\n\n# 산점도 : 2020년 데이터\nsns.pairplot(df1, height=2)\nplt.show()\n\n\n\n\n\n\n\n\n\n# 상관계수 : 2020년 데이터\n# 행복지수와 GDP 간 상관계수는 0.78로, 강한 양의 상관관계임\n# 행복지수와 Freedom 간 상관계수는 0.59로, 뚜렷한 양의 상관관계임\ncorr = df1.select_dtypes(include='number').corr()\ncorr['Score'].sort_values(ascending=False)\n\nScore             1.000000\nGDP_per_capita    0.775374\nFreedom           0.590597\nName: Score, dtype: float64\n\n\n\n# 상관분석 : 2020년 데이터\nplt.figure(figsize=(6, 4))\nsns.heatmap(corr, annot=True, cmap='Blues')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 2021년 데이터 전처리\ndf2 = df2021.copy()\ndf2.drop(['Social_support', 'Life_expectancy', 'Generosity'], axis=1, inplace=True)\ndf2.head()\n\n\n\n\n\n\n\n\nCountry\nScore\nGDP_per_capita\nFreedom\n\n\nRank\n\n\n\n\n\n\n\n\n1\nFinland\n7.842\n10.775\n0.949\n\n\n2\nDenmark\n7.620\n10.933\n0.946\n\n\n3\nSwitzerland\n7.571\n11.117\n0.919\n\n\n4\nIceland\n7.554\n10.878\n0.955\n\n\n5\nNetherlands\n7.464\n10.932\n0.913\n\n\n\n\n\n\n\n\n# 산점도 : 2021년 데이터\nsns.pairplot(df2, height=2, diag_kind='kde')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 상관분석 : 2021년 데이터\n# 행복지수와 GDP 간 상관계수는 0.79로, 강한 양의 상관관계임\n# 헹복지수와 Freedom 간 상관계수는 0.61로, 뚜렷한 양의 상관관계임\nplt.figure(figsize=(6, 4))\nsns.heatmap(df2.select_dtypes(include='number').corr(), annot=True, cmap='PuBuGn')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n결과 및 시사점\n\n행복지수와 GDP 간 관계는?\n\n상관계수는 2020년 0.78, 2021년 0.79로, 강한 양의 상관관계로 나타남\n경제 성장은 일반적으로 더 높은 소득과 향상된 생활 수준으로 이어지므로, 국민의 행복 수준도 높아지는 경향이 있음\n따라서 국민의 행복을 보장하기 위해, 국가의 GDP는 주요 우선순위 중 하나로 고려될 필요가 있음\n\n\n\n\n행복지수와 인생 선택의 자유 간 관계는?\n\n상관계수는 2020년 0.59, 2021년 0.61로, 뚜렷한 양의 상관관계로 나타남\n자유에 대한 인식은 지역과 문화에 따라 다양하기 때문에 일반화하기는 어려움\n그럼에도 불구하고, 개인이 삶을 선택할 자유를 얼마나 느끼는지는 국민의 행복 수준에 중요한 영향을 미침\n\n\n\n\n## (2-2) 행복 점수와 사회적 상태의 상관관계\n##       한 국가의 행복지수와 사회적 상태(Social.support)는 상관관계가 있는가?\n\n\n# 데이터 전처리\nx1 = df2020[['Generosity', 'Social_support', 'Score']].copy()\nx2 = df2021[['Generosity', 'Social_support', 'Score']].copy()\n\n\n# 상관분석 : 2020년 데이터\na1 = x1.corr()\nplt.figure(figsize=(6, 4))\nsns.heatmap(a1, annot=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n# 상관분석 : 2021년 데이터\na2 = x2.corr()\nplt.figure(figsize=(6, 4))\nsns.heatmap(a2, annot=True, cmap='GnBu')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n결과 및 시사점\n\n행복지수와 사회적 지지 간 관계는?\n\n상관계수는 2020년 0.77, 2021년 0.76으로, 강한 양의 상관관계로 나타남\n사회적 지지는 가족, 친구, 지인 등과 함께하는 관계에서 느끼는 정서적 지원에 대한 인식을 의미함\n일상 생활에서 가깝게 지내는 사람들과의 관계에서 형성되므로, 사회적 지지는 행복 수준에 중요한 요소임을 알 수 있음\n\n\n\n\n행복지수와 기부 문화 간 관계는?\n\n상관계수는 2020년 0.069, 2021년 -0.018로, 상관관계가 거의 없는 것으로 나타남\n따라서 기부 문화가 행복 수준과 직접적인 관련이 거의 없음을 확인할 수 있음\n\n\n\n\n## (2-3) 행복 점수와 전체 변수의 상관관계\n\n\n# 상관분석 : 2020년 데이터\ncorr = df2020.select_dtypes(include='number').corr()\n\nplt.figure(figsize=(8, 6))\nupp_mat = np.triu(corr)\nsns.heatmap(corr, mask=upp_mat,vmin=-1, vmax=1, annot=True, cmap ='RdYlBu_r', linewidths=4)\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\n\n# 상관분석 : 2021년 데이터\ncorr = df2021.select_dtypes(include='number').corr()\n\nplt.figure(figsize=(8, 6))\nupp_mat = np.triu(corr)\nsns.heatmap(corr, mask=upp_mat, vmin=-1, vmax=1,annot = True, cmap ='PiYG', linewidths=4)\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n결과 및 시사점\n\n2021년 행복지수에 가장 큰 영향을 미치는 요인은 경제적 여유(GDP, 0.79), 건강(0.77), 사회적 지지(0.76), 선택에 대한 자유도(0.61) 순으로 나타남\n기부 활동과 행복지수는 뚜렷한 관련이 없는 것으로 나타남\n1인당 GDP와 건강한 기대수명은 강한 양의 상관관계(0.86)가 있으므로, 경제적으로 여유로운 사람들이 더 건강하게 사는 경향이 있음을 알 수 있음"
  },
  {
    "objectID": "3_2_regression.html#단순선형-회귀분석",
    "href": "3_2_regression.html#단순선형-회귀분석",
    "title": "\n\n지도학습 : 회귀\n",
    "section": "8.2. 단순선형 회귀분석",
    "text": "8.2. 단순선형 회귀분석\n\n회귀(regression)\n\n지도학습의 한 종류로, 정답(label)이 수치형 변수일 때 사용됨\n하나 이상의 독립변수(x)가 종속변수(y)에 미치는 영향력의 크기를 수학적 관계식(모델)으로 추정하는 통계 기법\n\n독립변수(independent variable) : 다른 변수의 변화를 야기하는 변수\n종속변수(dependent variable) : 다른 변수의 영향으로 변화하는 변수\n\n학습된 모델은 새로운 독립변수 값에 대해 종속변수의 값을 예측할 수 있음\n독립변수 개수에 따른 구분\n\n단순선형 회귀(simple linear regression) : 독립변수가 1개인 경우\n다중선형 회귀(multiple linear regression) : 독립변수가 2개 이상인 경우\n\n\n\n\n\n회귀모델 평가지표 |지표|설명| |:———|:——————————| |MSE(Mean Squared Error)|- 평균제곱오차로, 작을수록 좋음| |RMSE(Root Mean Squared Error)|- MSE의 양의 제곱근으로, 작을수록 좋음 -단위가 데이터와 동일하여 해석이 용이함| |MAE(Mean Absolute Error)|- 평균절대오차로, 작을수록 좋음 - 이상값에 덜 민감함| |\\(R^2\\) (결정계수)|- 모델이 데이터의 변동을 얼마나 잘 설명하는지 나타내는 지표 - 0~1 사이의 값을 가지며, 1에 가까울수록 모델의 설명력이 높음|\n\n\n\n단순선형 회귀분석\n\n하나의 독립변수가 종속변수에 미치는 영향을 분석하는 통계 기법\n\n예 : 공부 시간(독립변수)에 따른 시험 성적(종속변수)의 변화\n\n단순선형 회귀모델 \\[y = \\beta_0 + \\beta_1x + \\epsilon\\]\n\n\\(\\beta_0\\) : 절편(intercept)\n\\(\\beta_1\\) : 기울기(slope)\n\\(\\epsilon\\) : 오차(error)\n\n회귀분석의 목적은 주어진 데이터를 가장 잘 설명하는 회귀선을 찾는 것\n\n일반적으로 오차의 제곱합을 최소화하는 최소제곱추정법(OLS; Ordinary Least Squares)을 사용함 \\[\\hat{y} = b_0 + b_1x\\]\n\n잔차(residual) : 관측값과 예측값의 차이, \\(y-\\hat{y}\\)\n\n\n\n\n\n\n# 한글 깨짐 현상에 대한 해결 방법\nimport matplotlib as mpl\nplt.rc('font', family='Malgun Gothic')\nmpl.rcParams['axes.unicode_minus'] = False\n\n\n# scikit-learn 설치하기\n#!pip install scikit-learn\n\n\n# scikit-learn의 linear_model 모듈에서 LinearRegression 클래스 불러오기\nfrom sklearn.linear_model import LinearRegression\n\n\n## 공부 시간(독립변수)에 따른 시험 성적(종속변수)의 변화\n# 데이터프레임 생성\ndata = pd.DataFrame({\n    'study_time': [2, 4, 6, 8, 10],\n    'score': [81, 93, 90, 97, 100]\n})\n\n# 산점도 : 두 변수 간 상관관계 확인\nplt.figure(figsize=(5, 3))\nplt.scatter(data['study_time'], data['score'])\nplt.xlabel('Study Time (hours)')\nplt.ylabel('Score')\nplt.show()\n\n# 독립변수, 종속변수 분리\n# scikit-Learn에서 입력 데이터(feature)를 2차원 배열로 요구함\nX = data[['study_time']]\ny = data['score']\n\n# 선형 회귀모형 객체 생성 및 학습\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# 7시간 공부했을 때, 시험 점수 예측\nnewdata = pd.DataFrame({'study_time': [7]})\npredicted_score = model.predict(newdata)\nprint(predicted_score)\n\n\n\n\n\n\n\n\n[94.3]"
  },
  {
    "objectID": "3_2_regression.html#실습-날씨-데이터-분석",
    "href": "3_2_regression.html#실습-날씨-데이터-분석",
    "title": "\n\n지도학습 : 회귀\n",
    "section": "8.3. (실습) 날씨 데이터 분석",
    "text": "8.3. (실습) 날씨 데이터 분석\n\n[데이터] 기상자료개방포털에서 제공하는 서울특별시의 기상 관측 데이터\n\n2010년 1월 ~ 2020년 12월\n날짜, 지점, 평균기온(℃), 최저기온(℃), 최고기온(℃)\n[실습파일] (2010-2020)_weather.csv\n\n\n\n\n2021년 8월 15일의 평균기온을 예측하면?\n\n\n\n## (1) 데이터 확인 및 전처리\n\n\n# 데이터 불러오기\nseoul = pd.read_csv('./data/(2010-2020)_weather.csv', encoding='cp949')\nseoul.head()\n\n\n\n\n\n\n\n\n날짜\n지점\n평균기온(℃)\n최저기온(℃)\n최고기온(℃)\n\n\n\n\n0\n2010-01-01\n108\n-7.6\n-12.7\n-3.6\n\n\n1\n2010-01-02\n108\n-3.6\n-7.4\n0.2\n\n\n2\n2010-01-03\n108\n-6.8\n-10.5\n-3.2\n\n\n3\n2010-01-04\n108\n-5.9\n-8.0\n-3.4\n\n\n4\n2010-01-05\n108\n-9.9\n-12.3\n-7.0\n\n\n\n\n\n\n\n\n# 데이터 정보\nseoul.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 4018 entries, 0 to 4017\nData columns (total 5 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   날짜       4018 non-null   object \n 1   지점       4018 non-null   int64  \n 2   평균기온(℃)  4018 non-null   float64\n 3   최저기온(℃)  4018 non-null   float64\n 4   최고기온(℃)  4017 non-null   float64\ndtypes: float64(3), int64(1), object(1)\nmemory usage: 157.1+ KB\n\n\n\n# 데이터 전처리 : 열 삭제\nseoul.drop('지점', axis=1, inplace=True)\n\n\n# 데이터 전처리 : 열 이름 변경\nseoul.columns = ['날짜', '평균기온', '최저기온', '최고기온']\n\n\n# 데이터 전처리 : 결측값 확인\nseoul.isna().sum()\n\n날짜      0\n평균기온    0\n최저기온    0\n최고기온    1\ndtype: int64\n\n\n\n# 데이터 전처리 : 결측값이 포함된 행 삭제\nseoul.dropna(axis=0, inplace=True)\n\n\n# 데이터 전처리 : 날짜 변수를 datetime 형식으로 변환\nseoul['날짜'] = pd.to_datetime(seoul['날짜'])\n\n\n# 데이터 전처리 : 새로운 변수(연도, 월, 일) 생성\nseoul['연도'] = seoul['날짜'].dt.year\nseoul['월']=seoul['날짜'].dt.month\nseoul['일']=seoul['날짜'].dt.day\nseoul.head()\n\n\n\n\n\n\n\n\n날짜\n평균기온\n최저기온\n최고기온\n연도\n월\n일\n\n\n\n\n0\n2010-01-01\n-7.6\n-12.7\n-3.6\n2010\n1\n1\n\n\n1\n2010-01-02\n-3.6\n-7.4\n0.2\n2010\n1\n2\n\n\n2\n2010-01-03\n-6.8\n-10.5\n-3.2\n2010\n1\n3\n\n\n3\n2010-01-04\n-5.9\n-8.0\n-3.4\n2010\n1\n4\n\n\n4\n2010-01-05\n-9.9\n-12.3\n-7.0\n2010\n1\n5\n\n\n\n\n\n\n\n\n# 데이터 전처리 : 8월 15일 데이터 선택\nconditions = (seoul['월']==8) & (seoul['일']==15)\nseoul0815 = seoul[conditions]\nseoul0815\n\n\n\n\n\n\n\n\n날짜\n평균기온\n최저기온\n최고기온\n연도\n월\n일\n\n\n\n\n226\n2010-08-15\n26.6\n24.6\n30.2\n2010\n8\n15\n\n\n591\n2011-08-15\n24.5\n22.9\n26.9\n2011\n8\n15\n\n\n957\n2012-08-15\n23.7\n22.4\n27.1\n2012\n8\n15\n\n\n1322\n2013-08-15\n28.7\n25.8\n32.4\n2013\n8\n15\n\n\n1687\n2014-08-15\n24.9\n20.9\n29.6\n2014\n8\n15\n\n\n2052\n2015-08-15\n27.1\n23.1\n30.8\n2015\n8\n15\n\n\n2418\n2016-08-15\n29.1\n25.8\n34.0\n2016\n8\n15\n\n\n2783\n2017-08-15\n21.9\n20.8\n24.0\n2017\n8\n15\n\n\n3148\n2018-08-15\n31.7\n28.3\n38.0\n2018\n8\n15\n\n\n3513\n2019-08-15\n25.9\n23.9\n28.6\n2019\n8\n15\n\n\n3879\n2020-08-15\n26.1\n25.0\n27.0\n2020\n8\n15\n\n\n\n\n\n\n\n\n\n## (2) 데이터 분석 및 시각화\n\n\n# 요약 통계량\nseoul.describe()\n\n\n\n\n\n\n\n\n날짜\n평균기온\n최저기온\n최고기온\n연도\n월\n일\n\n\n\n\ncount\n4017\n4017.000000\n4017.000000\n4017.000000\n4017.000000\n4017.000000\n4017.000000\n\n\nmean\n2015-07-02 07:01:34.100074752\n12.965596\n8.991063\n17.699627\n2015.000249\n6.521782\n15.731392\n\n\nmin\n2010-01-01 00:00:00\n-14.800000\n-18.000000\n-10.700000\n2010.000000\n1.000000\n1.000000\n\n\n25%\n2012-10-01 00:00:00\n3.700000\n-0.300000\n8.200000\n2012.000000\n4.000000\n8.000000\n\n\n50%\n2015-07-02 00:00:00\n14.300000\n9.800000\n19.600000\n2015.000000\n7.000000\n16.000000\n\n\n75%\n2018-04-02 00:00:00\n22.800000\n18.900000\n27.400000\n2018.000000\n10.000000\n23.000000\n\n\nmax\n2020-12-31 00:00:00\n33.700000\n30.300000\n39.600000\n2020.000000\n12.000000\n31.000000\n\n\nstd\nNaN\n10.805008\n10.934039\n10.976719\n3.163104\n3.449203\n8.802435\n\n\n\n\n\n\n\n\n# 산점도 : 연도에 따른 평균기온 변화\n# 독립변수, 종속변수 분리\n# scikit-learn에서 입력 데이터(feature)를 2차원 배열로 요구함\nX = seoul0815[['연도']]\ny = seoul0815['평균기온']\n\nfig = plt.figure(figsize=(5, 3))\nplt.scatter(X, y)\nplt.xlabel('연도')\nplt.ylabel('평균기온')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 상관계수 : 연도와 평균기온의 상관관계\n# 연도와 평균기온은 약한 양의 상관관계로 나타나, 단순선형 회귀모형을 적합할 수 있음\nseoul0815[['연도', '평균기온']].corr()\n\n\n\n\n\n\n\n\n연도\n평균기온\n\n\n\n\n연도\n1.000000\n0.194953\n\n\n평균기온\n0.194953\n1.000000\n\n\n\n\n\n\n\n\n# 단순선형 회귀분석 : 2021년 8월 15일 평균기온 예측\n# 선형 회귀모델 생성 및 학습\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# 회귀식의 절편 및 기울기\nintercept = model.intercept_\nslope = model.coef_\nprint(f'회귀식: hat(y) = {model.intercept_:.2f} + {model.coef_[0]:.2f}*x')\n\n# 결정계수\nR2 = model.score(X, y)\nprint(f'결정계수 : {R2:.3f}')\n\n# 2021년일 때, 평균기온 예측\nnewdata = pd.DataFrame({'연도': [2022]})\ny_pred = model.predict(newdata)\nprint(f'2021년 8월 15일 평균기온 예측값 : {y_pred[0]:.2f}')\n\n회귀식: hat(y) = -297.85 + 0.16*x\n결정계수 : 0.038\n2021년 8월 15일 평균기온 예측값 : 27.51\n\n\n\n# 산점도와 단순선형 회귀선\nfig = plt.figure(figsize=(5, 3))   \nsns.regplot(x='연도', y='평균기온', data=seoul0815)\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n결과 및 시사점\n\n연도와 평균기온은 약한 양의 상관관계(r=0.195)로 나타나, 단순선형 회귀모형을 적합할 수 있음\n독립변수는 연도, 종속변수는 평균기온으로 단순선형 회귀분석을 실시한 결과, 모형의 설명력은 3.8%로 비교적 낮게 나타남\n적합된 회귀식 : \\(\\hat{y} = -297.85 + 0.16*x\\)\n\n연도가 1년 증가할수록 8월 15일의 평균기온은 약 0.16℃ 상승하는 것으로 추정됨\n\n따라서 2021년 8월 15일의 평균기온은 27.51℃로 예측됨"
  },
  {
    "objectID": "3_2_regression.html#다중선형-회귀분석",
    "href": "3_2_regression.html#다중선형-회귀분석",
    "title": "\n\n지도학습 : 회귀\n",
    "section": "8.4. 다중선형 회귀분석",
    "text": "8.4. 다중선형 회귀분석\n\n다중선형 회귀분석\n\n두 개 이상의 독립변수가 종속변수에 미치는 영향을 분석하는 통계 기법\n\n예: 공부 시간, 수면 시간, 강의 출석률(독립변수들)에 따른 시험 성적(종속변수)의 변화\n\n다중선형 회귀모델 \\[y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_p x_p + \\epsilon\\]\n\n\\(\\beta_0\\) : 절편(intercept)\n\n\\(\\beta_1, \\beta_2, \\dots, \\beta_p\\) : 각 독립변수의 기울기(slope)\n\\(\\epsilon\\) : 오차(error)"
  },
  {
    "objectID": "3_2_regression.html#실습-캘리포니아-주택-가격-분석",
    "href": "3_2_regression.html#실습-캘리포니아-주택-가격-분석",
    "title": "\n\n지도학습 : 회귀\n",
    "section": "8.5. (실습) 캘리포니아 주택 가격 분석",
    "text": "8.5. (실습) 캘리포니아 주택 가격 분석\n\n[데이터] scikit-learn에서 제공하는 캘리포니아 주택 가격 데이터\n\n1990년대 캘리포니아 지역의 주택 가격에 대한 데이터\n총 20,640개의 관측값과 8개의 독립변수(feature), 1개의 종속변수(target)으로 구성됨\nas_frame=True 옵션을 사용하면 독립변수와 종속변수를 DataFrame 형태로 불러올 수 있음\nas_frame=False 옵션(기본값)을 사용하면 독립변수와 종속변수를 각각 넘파이 배열 형태로 별도로 제공함\n\n\n\n\n\n\n변수\n설명\n\n\n\n\nMedInc\n지역 중위 소득 (10,000 USD)\n\n\nHouseAge\n주택 연식 (건축 후 경과된 연도 수)\n\n\nAveRooms\n가구당 평균 방 개수\n\n\nAveBedrms\n가구당 평균 침실 개수\n\n\nPopulation\n지역 내 인구 수\n\n\nAveOccup\n가구당 평균 거주 인원 수\n\n\nLatitude\n위도\n\n\nLongitude\n경도\n\n\nMedHouseVal\n주택 중위 가격 (100,000 USD)\n\n\n\n\n\n## (1) 데이터 확인 및 전처리\n\n\n# 데이터 불러오기\nfrom sklearn.datasets import fetch_california_housing\ndata = fetch_california_housing(as_frame=True)\ndf = data.frame\ndf.head()\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\nMedHouseVal\n\n\n\n\n0\n8.3252\n41.0\n6.984127\n1.023810\n322.0\n2.555556\n37.88\n-122.23\n4.526\n\n\n1\n8.3014\n21.0\n6.238137\n0.971880\n2401.0\n2.109842\n37.86\n-122.22\n3.585\n\n\n2\n7.2574\n52.0\n8.288136\n1.073446\n496.0\n2.802260\n37.85\n-122.24\n3.521\n\n\n3\n5.6431\n52.0\n5.817352\n1.073059\n558.0\n2.547945\n37.85\n-122.25\n3.413\n\n\n4\n3.8462\n52.0\n6.281853\n1.081081\n565.0\n2.181467\n37.85\n-122.25\n3.422\n\n\n\n\n\n\n\n\n# 데이터 정보\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 20640 entries, 0 to 20639\nData columns (total 9 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   MedInc       20640 non-null  float64\n 1   HouseAge     20640 non-null  float64\n 2   AveRooms     20640 non-null  float64\n 3   AveBedrms    20640 non-null  float64\n 4   Population   20640 non-null  float64\n 5   AveOccup     20640 non-null  float64\n 6   Latitude     20640 non-null  float64\n 7   Longitude    20640 non-null  float64\n 8   MedHouseVal  20640 non-null  float64\ndtypes: float64(9)\nmemory usage: 1.4 MB\n\n\n\n# 데이터 전처리 : 결측값 확인\ndf.isna().sum()\n\nMedInc         0\nHouseAge       0\nAveRooms       0\nAveBedrms      0\nPopulation     0\nAveOccup       0\nLatitude       0\nLongitude      0\nMedHouseVal    0\ndtype: int64\n\n\n\n# 데이터 전처리 : 훈련 데이터와 평가 데이터로 분할 (7:3 비율)\ncalifornia = fetch_california_housing()\nX = california.data\ny = california.target\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n\n\n## (2) 데이터 분석 및 시각화\n\n\n# 요약 통계량 확인\ndf_train = pd.DataFrame(data=X_train, columns=california.feature_names)\ndf_train['MedHouseVal'] = y_train\ndf_train.describe()\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\nMedHouseVal\n\n\n\n\ncount\n14448.000000\n14448.000000\n14448.000000\n14448.000000\n14448.000000\n14448.000000\n14448.000000\n14448.000000\n14448.000000\n\n\nmean\n3.876892\n28.575374\n5.438125\n1.098033\n1427.927326\n3.119236\n35.650669\n-119.584102\n2.069240\n\n\nstd\n1.904908\n12.613634\n2.453569\n0.447498\n1140.225190\n12.373636\n2.135742\n2.002930\n1.157492\n\n\nmin\n0.499900\n1.000000\n0.888889\n0.333333\n3.000000\n0.692308\n32.550000\n-124.350000\n0.149990\n\n\n25%\n2.567225\n18.000000\n4.448928\n1.006783\n791.000000\n2.430380\n33.940000\n-121.800000\n1.193000\n\n\n50%\n3.539100\n29.000000\n5.232422\n1.049492\n1168.000000\n2.817147\n34.270000\n-118.510000\n1.793000\n\n\n75%\n4.758075\n37.000000\n6.060692\n1.100328\n1727.000000\n3.279135\n37.720000\n-118.010000\n2.646000\n\n\nmax\n15.000100\n52.000000\n141.909091\n25.636364\n35682.000000\n1243.333333\n41.950000\n-114.310000\n5.000010\n\n\n\n\n\n\n\n\n# 산점도\nsns.pairplot(df_train, diag_kind='kde')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 상관분석\ncorr_train = df_train.corr()\nupp_mat = np.triu(corr_train)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr_train, annot=True, mask=upp_mat, cmap='BrBG', vmin=-1, vmax=1)\nplt.title('Correlation Matrix')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 상관관계가 강한 독립변수 선택\n# scikit-learn에서 입력 데이터(feature)를 2차원 배열로 요구함\nfeatures = ['MedInc', 'HouseAge', 'AveRooms', 'Latitude']\ntarget = 'MedHouseVal'\n\nX_train = df_train[features]\ny_train = df_train[target]\n\n\n# 평가 데이터에서도 훈련 데이터에서 사용한 독립변수만 선택\ndf_test = pd.DataFrame(data=X_test, columns=california.feature_names)\ndf_test['MedHouseVal'] = y_test\nX_test = df_test[features]\n\n\n# 선형 회귀모델 생성 및 학습\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# 회귀모델 평가 : 결정계수, MSE\nfrom sklearn.metrics import mean_squared_error, r2_score\ny_pred = model.predict(X_test)\nR2 = r2_score(y_test, y_pred)\nRMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n\nprint(f\"결정계수 : {R2:.3f}\")\nprint(f\"RMSE : {RMSE:.3f}\")\n\n결정계수 : 0.520\nRMSE : 0.794\n\n\n\n# 회귀계수\ndf_coef = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_})\nprint(df_coef)\n\n    Feature  Coefficient\n0    MedInc     0.435658\n1  HouseAge     0.016937\n2  AveRooms    -0.019505\n3  Latitude    -0.045071\n\n\n\n# statsmodels 라이브러리 설치\n#!pip install statsmodels\n\n\n# [참고] 회귀계수의 유의성\nimport statsmodels.api as sm\n\nX_train_const = sm.add_constant(X_train)\nols_model = sm.OLS(y_train, X_train_const).fit()\nprint(ols_model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:            MedHouseVal   R-squared:                       0.519\nModel:                            OLS   Adj. R-squared:                  0.518\nMethod:                 Least Squares   F-statistic:                     3890.\nDate:                Thu, 24 Jul 2025   Prob (F-statistic):               0.00\nTime:                        02:36:22   Log-Likelihood:                -17332.\nNo. Observations:               14448   AIC:                         3.467e+04\nDf Residuals:                   14443   BIC:                         3.471e+04\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.6091      0.115     13.957      0.000       1.383       1.835\nMedInc         0.4357      0.004    116.405      0.000       0.428       0.443\nHouseAge       0.0169      0.001     31.487      0.000       0.016       0.018\nAveRooms      -0.0195      0.003     -6.652      0.000      -0.025      -0.014\nLatitude      -0.0451      0.003    -14.213      0.000      -0.051      -0.039\n==============================================================================\nOmnibus:                     3079.717   Durbin-Watson:                   1.979\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             8182.373\nSkew:                           1.148   Prob(JB):                         0.00\nKurtosis:                       5.884   Cond. No.                         809.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n결과 및 시사점\n\n결정계수 \\(R^2\\)은 52.0%로 나타남\nRMSE는 0.630으로, 주택 중위 가격의 실제값과 예측값이 평균적으로 약 6만 달러 차이가 있다는 것을 의미함\n훈련 데이터에서 주택 중위 가격의 평균은 약 20만 달러인 점을 고려하면, 모델의 평균 오차는 약 30% 수준임을 알 수 있음\n따라서 평균 오차가 비교적 큰 편이므로, 모델 성능 개선이 필요한 것으로 판단됨\n회귀계수를 살펴보면 지역 중위 소득, 주택 연식이 증가할수록 주택 중위 가격은 높아지며, 가구당 평균 거주 인원 수, 위도가 증가할수록 주택 중위가격은 낮아지는 것으로 나타남"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]