---
jupyter: python3
---

<h1>8. 지도학습 : 회귀</h1>

## 8.1. 상관분석
### 8.1.1. 상관계수
+ 상관분석(correlation analysis)
  + 두 수치형 변수 간 선형적인 관계(linear relationship)를 파악하는 통계 기법
  + 상관계수(correlation coefficient)
    + 두 변수 간 상관관계를 수치로 나타내어 정량화한 지표
    + 상관계수의 절대값은 선형성의 강도를, 부호는 선형성의 방향성을 나타냄
    + 변수의 측정 단위의 영향을 받지 않음

<br>

+ 상관계수의 성질
  + 상관계수 r은 항상 -1에서 +1 사이의 값을 가짐
  + 절대값이 1에 가까울수록 강한 상관관계를 의미함
  + r>0이면 양의 상관관계, r<0이면 음의 상관관계, r=0이면 상관관계가 없음을 나타냄
    + 양의 상관관계 : 한 변수가 증가할 때 다른 변수도 증가
    + 음의 상관관계 : 한 변수가 증가할 때 다른 변수는 감소
    + 상관관계 없음 : 한 변수가 증가할 때 다른 변수는 영향을 받지 않음

<br>

![](./images/fig3-6.jpg){width=70%}

<br>

### 8.1.2. (실습) 행복지수 데이터 분석
+ \[데이터\] 캐글에서 제공하는 전세계 행복지수 데이터
  + 평가지표 : 1인당 GDP, 사회적 지지 정도, 건강한 기대수명, 인생 선택의 자유, 기부
  + \[실습파일\] [2020.csv](./data/2020.csv), [2021.csv](./data/2021.csv)

<br>

> **행복지수와 관련된 요인은 무엇일까?**

<br>

```{python}
## (1) 데이터 확인 및 전처리
```

```{python}
# 라이브러리 불러오기
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
```

```{python}
# 데이터 불러오기
df2020 = pd.read_csv('./data/2020.csv', index_col=0)
df2021 = pd.read_csv('./data/2021.csv', index_col=0)
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 열 정보
df2020.dtypes
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 238}
# 2020년 데이터 확인
df2020.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 238}
# 2021년 데이터 확인
df2021.head()
```

```{python}
# 데이터 전처리 : 열 삭제
df2020.drop(['upperwhisker', 'lowerwhisker', 'Dystopia'], axis=1, inplace=True)
df2021.drop(['upperwhisker', 'lowerwhisker', 'Dystopia'], axis=1, inplace=True)
```

```{python}
# 열 이름 변경 : 공백을 .으로 대체
#df2020.columns = df2020.columns.str.replace(' ','.')
#df2021.columns = df2021.columns.str.replace(' ','.')
```

```{python}
# 열 이름 변경
df2020.columns = ['Country', 'Score', 'GDP.per.capita', 'Social.support', 'Life.expectancy', 'Freedom', 'Generosity']
df2021.columns = ['Country', 'Score', 'GDP.per.capita', 'Social.support', 'Life.expectancy', 'Freedom', 'Generosity']
```

<br>

```{python}
## (2) 데이터 분석 및 시각화
## (2-1) 행복 점수와 기능의 상관관계
##       한 국가의 행복지수와 경제적(GDP), 법적 상태(Freedom)는 상관관계가 있는가?
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 455}
# 2020년 데이터 전처리
df1 = df2020.copy()
df1.drop(['Social.support', 'Life.expectancy', 'Generosity'], axis=1, inplace=True)
df1.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 상관관계 : 2020년 데이터
# 행복지수와 GDP 간 상관계수는 0.78로, 강한 양의 상관관계임
# 행복지수와 Freedom 간 상관계수는 0.59로, 뚜렷한 양의 상관관계임
corr = df1.select_dtypes(include='number').corr()
corr['Score'].sort_values(ascending=False)
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 396}
# 히트맵 : 2020년 데이터
plt.figure(figsize=(6, 4))
sns.heatmap(corr, annot=True, cmap='Blues')
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 455}
# 2021년 데이터 전처리
df2 = df2021.copy()
df2.drop(['Social.support', 'Life.expectancy', 'Generosity'], axis=1, inplace=True)
df2.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 396}
# 히트맵 : 2021년 데이터
# 행복지수와 GDP 간 상관계수는 0.79로, 강한 양의 상관관계임
# 헹복지수와 Freedom 간 상관계수는 0.61로, 뚜렷한 양의 상관관계임
plt.figure(figsize=(6, 4))
sns.heatmap(df2.select_dtypes(include='number').corr(), annot=True, cmap='PuBuGn')
plt.show()
```

<br>

##### 결과 및 시사점
+ 행복지수와 GDP 간 관계는?
  + 상관계수는 2020년 0.78, 2021년 0.79로, 강한 양의 상관관계로 나타남
  + 경제 성장은 보통 더 높은 소득과 향상된 생활 수준으로 이어지므로, 국민의 행복 수준도 높아지는 경향이 있음
  + 따라서 국민의 행복을 보장하기 위해, 국가의 GDP는 주요 우선순위 중 하나로 고려될 필요가 있음

<br>

+ 행복지수와 인생 선택의 자유 간 관계는?
  + 상관계수는 2020년 0.59, 2021년 0.61로, 뚜렷한 양의 상관관계로 나타남
  + 자유에 대한 인식은 지역과 문화에 따라 다양하기 때문에 일반화하기는 어려움
  + 그럼에도 불구하고, 개인이 삶을 선택할 자유를 얼마나 느끼는지는 국민의 행복 수준에 중요한 영향을 미침

<br>

```{python}
## (2-2) 행복 점수와 사회적 상태의 상관관계
##       한 국가의 행복지수와 사회적 상태(Social.support)는 상관관계가 있는가?
```

```{python}
# 데이터 전처리
x1 = df2020[['Generosity', 'Social.support', 'Score']].copy()
x2 = df2021[['Generosity', 'Social.support', 'Score']].copy()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 396}
# 히트맵 : 2020년 데이터
a1 = x1.corr()
plt.figure(figsize=(6, 4))
sns.heatmap(a1, annot=True)
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 396}
# 히트맵 : 2021년 데이터
a2 = x2.corr()
plt.figure(figsize=(6, 4))
sns.heatmap(a2, annot=True, cmap='GnBu')
plt.show()
```

<br>

##### 결과 및 시사점
+ 행복지수와 사회적 지지 간 관계는?
  + 상관계수는 2020년 0.77, 2021년 0.76으로, 강한 양의 상관관계로 나타남
  + 사회적 지지는 가족, 친구, 지인 등과 함께하는 관계에서 느끼는 정서적 지원에 대한 인식을 의미함
  + 일상 생활에서 가깝게 지내는 사람들과의 관계에서 형성되므로, 사회적 지지는 행복 수준에 중요햔 요소임을 알 수 있음

<br>

+ 행복지수와 기부 문화 간 관계는?
  + 상관계수는 2020년 0.069, 2021년 -0.018로, 상관관계가 거의 없는 것으로 나타남
  + 따라서 기부 문화가 행복 수준과 직접적인 관련이 거의 없음을 확인할 수 있음

<br>

```{python}
## (2-3) 행복 점수와 전체 변수의 상관관계
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 580}
# 전체 상관계수 : 2020년 데이터
corr = df2020.select_dtypes(include='number').corr()

plt.figure(figsize=(8, 6))
upp_mat = np.triu(corr)
sns.heatmap(corr, mask=upp_mat,vmin=-1, vmax=1, annot=True, cmap ='RdYlBu_r', linewidths=4)
plt.xticks(rotation=45)
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 580}
# 전체 상관계수 : 2021년 데이터
corr = df2021.select_dtypes(include='number').corr()

plt.figure(figsize=(8, 6))
upp_mat = np.triu(corr)
sns.heatmap(corr, mask=upp_mat, vmin=-1, vmax=1,annot = True, cmap ='PiYG', linewidths=4)
plt.xticks(rotation=45)
plt.show()
```

<br>

##### 결과 및 시사점
+ 행복지수에 가장 큰 영향을 미치는 요인은 경제적 여유(GDP, 0.79), 건강(0.77), 사회적 지지(0.76), 선택에 대한 자유도(0.61) 순으로 나타남
+ 기부 활동과 행복지수는 뚜렷한 관련이 없는 것으로 나타남
+ 1인당 GDP와 건강한 기대수명은 강한 양의 상관관계(0.86)가 있으므로, 경제적으로 여유로운 사람들이 더 건강하게 사는 경향이 있음을 알 수 있음

<br>

<br>

## 8.2. 회귀분석

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 한글 깨짐 현상에 대한 해결 방법
import matplotlib.pyplot as plt
import matplotlib as mpl

plt.rc('font', family='Malgun Gothic')  # 또는 '맑은 고딕'
mpl.rcParams['axes.unicode_minus'] = False
```

```{python}
# scikit-learn 설치하기
#!pip install scikit-learn
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 284}
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# 공부시간 : 독립변수, 시험점수 : 종속변수
x = [[2],[4],[6],[8],[10]]       # 공부시간
y = [[81],[93],[90],[97],[100]]  # 시험점수

# 산점도 그래프
plt.scatter(x,y)
plt.show()

# 학습시키기
model = LinearRegression()      # 선형회귀분석 객체 생성하기

# 선형회귀분석 객체를 이용하여 학습시키기
model.fit(x,y)

# 예측하기
result = model.predict([[7]])   # 7시간 학습
print(f'예상점수:{result}')
```

<br>

### 8.2.1. 단순선형 회귀분석

<br>

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 206}
# 데이터 불러오기
seoul = pd.read_csv('./data/(2010-2020) weather.csv', encoding='cp949')
seoul.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
seoul.info()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 300}
seoul.describe()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 206}
# 지점 변수 삭제
seoul.drop('지점', axis=1, inplace=True)
seoul.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 206}
seoul.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 열 이름 변경
seoul.columns = ['날짜', '평균기온', '최저기온', '최고기온']
seoul.columns
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
seoul.isnull().sum()
```

```{python}
# 결측값을 포함하는 행 삭제
seoul.dropna(subset=['최고기온'], axis=0, inplace=True)
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
seoul.info()
```

```{python}
seoul['날짜'] = pd.to_datetime(seoul['날짜'])
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 206}
# 열 추가
seoul['연도'] = seoul['날짜'].dt.year
seoul['월']=seoul['날짜'].dt.month
seoul['일']=seoul['날짜'].dt.day
seoul.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 394}
# 필터링
conditions = (seoul['날짜'].dt.month==8) & (seoul['날짜'].dt.day==15)
seoul0815 = seoul[conditions]
seoul0815
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
seoul0815.info()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 결측값 확인
seoul0815.isnull().sum()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 444}
# 연도에 따른 평균기온 변화
fig = plt.figure(figsize=(5, 3))
X = seoul0815[['연도']]
Y = seoul0815['평균기온']
plt.xlabel('연도')
plt.ylabel('평균기온')
plt.scatter(X, Y)
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 869}
# jointplot 그리기
sns.jointplot(x='연도', y ='평균기온', kind='reg', data=seoul0815)
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 단순선형 회귀분석 : 2022년 8월 15일 기온 예측
model = LinearRegression()
X = seoul0815[['연도']]
Y = seoul0815['평균기온']
model.fit(X, Y)

future = pd.DataFrame({'연도': [2022]})
result = model.predict(future)
print(result)   
```

<br>

+ fit() 메서드는 선형 회귀 모델에 필요한 두 가지 변수를 전달
  + 기울기: line_fitter.coef_
  + 절편: line_fitter.intercept_
  + 이렇게 하면 새로운 X 값을 넣어 y값을 예측할 수 있게 됨
  + 싸이킷런 단순 선형회귀에서는 최소제곱법(Ordinary Least Squares)을 활용하기 때문

<br>

```{python}
#| colab: {base_uri: https://localhost:8080/}
seoul0815.info()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 444}
# 8월 15일 평균기온을 산점도, 회귀선 출력하기
x=seoul0815['연도']
y=seoul0815['평균기온']

fp1 = np.polyfit(x, y,2)
f1 = np.poly1d(fp1)
fx = np.linspace(2010, 2020)

plt.figure(figsize=(5, 3))
plt.scatter(x,y)
plt.plot(fx, f1(fx), ls='dashed', lw=3, color='g')

plt.xlabel('연도')
plt.ylabel('평균기온')
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
fp1
f1
fx
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 444}
# 시본 모듈로 추세선 넣기
fig = plt.figure(figsize=(5, 3))   
sns.regplot(x='연도', y='평균기온', data=seoul0815) 
plt.grid()
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 461}
sns.jointplot(x='연도', y='평균기온', data=seoul0815, kind='reg')
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 728}
sns.pairplot(seoul0815, kind='reg')
plt.show()
```

<br>

### 8.2.2. 다중선형 회귀분석

<br>

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 426}
seoul.info()
seoul.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
from sklearn.linear_model import LinearRegression
model = LinearRegression()

X = seoul0815[['연도','최저기온','최고기온']]
Y = seoul0815['평균기온']

model.fit(X, Y)
new_data = pd.DataFrame({'연도': [2022], '최저기온': [24], '최고기온': [33]})
result = model.predict(new_data)
print(result)
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 502}
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import seaborn as sns
plt.figure(figsize=(10,3))

# 데이터 준비 : 속성(변수) 2가지 선택
X = seoul[['연도','최저기온','최고기온']]
Y = seoul['평균기온']

# 먼저 X와 Y변수를 받아 사이킷런의 train_test_split함수를 통해 7:3의 비율로 데이터를 분할한다.
x_train, x_test, y_train, y_test = train_test_split(X,Y, train_size = 0.7, test_size = 0.3)

#다중 선형 회귀 모델 생성
model = LinearRegression()
model.fit(x_train, y_train)

# 모델 테스트하기 : test셋의 일부 데이터를 가지고 모델의 예측결과가 얼마나 좋게 나타나는지 확인
plt.plot(model.predict(x_test[:50]), label='predict')
plt.plot(y_test[:50].values.reshape(-1, 1), label='real temp')
plt.legend()
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 502}
# 전체 데이터를 이용해 값을 예측하고 실제 값과 비교하여 산점도 그리기
plt.figure(figsize=(10, 3))
y_predict = model.predict(x_test)
plt.scatter(y_test, y_predict, alpha = 0.4)
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# score 메소드를 통해 다중선형회귀 모델의 성능을 측정
print(model.score(x_train,y_train))
# 결정계수 R²의 최댓값은 1이며 이 수치가 클수록 실제값과 예측값이 유사함을 의미한다.
# 우리가 모델링한 다중선형회귀모델은 약 0.99의 결정계수를 가지며 
# 이는 X변수들이 y변수에 미치는 영향이 99%로 X변수들이 평균기온값 변동의 99%를 설명할 수 있다는 뜻임
```

