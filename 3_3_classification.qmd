---
jupyter: python3
---

<h1>9. 분류</h1>

## 9.1. K-최근접 이웃
+ 분류(classification)
  + 지도학습의 한 종류로, 라벨(label)이 있는 데이터를 기반으로 각 데이터가 속하는 집단(category) 간의 관계를 학습함
  + 학습된 모델은 새로운 데이터가 어떤 집단에 속하는지 자동으로 판별할 수 있음
  + 대표적인 알고리즘으로는 k-최근접 이웃(K-NN), 의사결정트리(decision tree), 나이브 베이즈(naive bayes), 서포트 벡터 머신(SVM) 등이 있음
  + 활용 사례: 스팸 문자 분류, 수능 점수 기반 등급 판별, 의료 진단(암 유무 판별), 이미지 속 객체 인식(강아지와 고양이 분류)  

<br>

+ K-최근접 이웃(K-Nearest Neighbors)
  + 입력된 데이터로부터 거리가 가까운 k개의 기존 데이터 레이블을 참조하여 가장 많이 속한 라벨로 입력된 데이터를 라벨링하는 방법
  + 일반적으로 k의 개수는 동점 상황을 만들지 않기 위해 홀수로 지정함
  + 거리 계산에는 보통 유클리디안 거리(Euclidean distance)를 사용함

![](./images/fig3-9.jpg){width=50%}

<br>

+ k의 수
  + K-NN 알고리즘은 탐색할 이웃의 개수(k)에 따라 분류가 달라질 수 있음
    + k가 너무 크면, 데이터의 세세한 패턴을 반영하지 못해 과소적합(underfitting)이 발생함
    + k가 너무 작으면, 개별 데이터에 민감하게 반응하여 과적합(overfitting)이 발생함
  + 일반적으로 최적의 k 값은 교차검증(cross-validation)을 통해 테스트 오차(test error)를 최소홯는 값으로 결정함

![](./images/fig3-10.jpg){width=70%}

<br>

```{python}
# 라이브러리 불러오기
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 448}
# 원두맛에 대한 데이터 생성
from sklearn.neighbors import KNeighborsClassifier
x = [4, 5, 10, 4, 3, 11, 14 , 8, 10, 12] 
y = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]
classes = [0, 0, 1, 0, 0, 1, 1, 0, 1, 1]

plt.style.use('default')
plt.scatter(x, y, c=classes)
plt.show()
data = list(zip(x, y))
print(data)
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 448}
# k=1
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(data, classes)
new_x = 8
new_y = 21
new_point = [(new_x, new_y)]
prediction = knn.predict(new_point)
print(prediction)
plt.scatter(x + [new_x], y + [new_y], c=classes + [prediction[0]])
plt.text(x=new_x-1.7, y=new_y-0.7, s=f"new point, class: {prediction[0]}")
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 430}
# k=5
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(data, classes)
prediction = knn.predict(new_point)
print(prediction)
plt.scatter(x + [new_x], y + [new_y], c=classes + [prediction[0]])
plt.text(x=new_x-1.7, y=new_y-0.7, s=f"new point, class: {prediction[0]}")
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 교차검증으로 k찾기
from sklearn.model_selection import cross_val_score

knn=KNeighborsClassifier()
scores=cross_val_score(knn,data,classes,cv=3, scoring='accuracy')

for i in range(scores.size):
    print(f"{i+1}번째 정확도: {scores[i]}")
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 394}
# 표준화 예제 데이터 생성
df = pd.DataFrame({'A' : np.arange(11), 'B' : np.arange(11) ** 2})
df
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 394}
# Standard Scaler
from sklearn.preprocessing import StandardScaler
standardScaler = StandardScaler()
df_standardScaled = standardScaler.fit_transform(df)
pd.DataFrame(df_standardScaled, columns = ['A_std', 'B_std'])
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 394}
#MinMaxScaler
from sklearn.preprocessing import MinMaxScaler
minmaxScaler = MinMaxScaler()

df_minmaxScaled = minmaxScaler.fit_transform(df)
pd.DataFrame(df_minmaxScaled, columns = ['A_minmax', 'B_minmax'])
```

<br>

## 9.2. (실습) 드라마 분류

<br>

```{python}
#| scrolled: true
# 11.2 드라마분류하기
df = pd.read_csv('./data/chap11_movie_genre_final.csv')
df.head(3)
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
df.info()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 639}
plt.figure(figsize=(8, 3))
sns.histplot(df['target'], bins=20, kde=True)
plt.title("movie count")
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 639}
plt.figure(figsize=(8, 3))
sns.histplot(df['vote_average'], bins=20, kde=True)
plt.title("vote_average")
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
print(df.columns)
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
count_list=[]
genre_list=['Action', 'Adventure','Fantasy', 'ScienceFiction', 'Crime', 'Drama', 'Thriller', 'Animation','Family', 'Western', 'Comedy', 'Romance', 'Horror', 'Mystery','History', 'War', 'Music', 'Documentary', 'Foreign', 'TVMovie']

for i in genre_list:
  count_list.append(len(df[df[i]==1]))

count_list
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 891}
plt.figure(figsize=(5, 5))
plt.barh(genre_list,count_list,color=sns.color_palette('hls',20))
plt.show()
```

```{python}
for i in range(len(genre_list)):
  print(f'{genre_list[i]} : {count_list[i]}')
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
temp = (df.Drama==1)&(df.vote_average>=6.5)
df[temp]
print(f'드라마 장르 영화 2281편 중 평점 6.5 이상:{len(df[temp])}편')
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
temp = (df.Comedy==1)&(df.vote_average>=6.5)
df[temp]
print(f'코메디 장르 영화 1714편 중 평점 6.5 이상:{len(df[temp])}편')
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
temp = (df.Thriller==1)&(df.vote_average>=6.5)
df[temp]
print(f'스릴러 영화 1270편 중 평점 6.5 이상:{len(df[temp])}편')
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
temp = (df.Action==1)&(df.vote_average>=6.5)
df[temp]
print(f'액션 영화 1140편 중 평점 6.5 이상:{len(df[temp])}편')
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
1208/2218
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
521/1714
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
415/1270
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
355/1140
```

```{python}
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
x=df[['Action', 'Adventure', 'Fantasy', 'ScienceFiction', 'Crime', 'Drama', 'Thriller', 'Animation', 'Family', 'Western', 'Comedy', 'Romance', 'Horror', 'Mystery', 'History', 'War', 'Music', 'Documentary', 'Foreign', 'TVMovie']]
y=df[['target']]
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2)
print(x_train.shape)
print(x_test.shape)
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
from sklearn.model_selection import cross_val_score
knn = KNeighborsClassifier()
scores=cross_val_score(knn, x_train, y_train, cv=2, scoring='accuracy')

for i in range(scores.size):
    print(f"{i+1}번째 정확도: {scores[i]}")
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
from sklearn.neighbors import KNeighborsClassifier

neigh=KNeighborsClassifier(n_neighbors=5)
neigh.fit(x_train, y_train)
print(neigh.classes_)
print(f'거리계산방법: {neigh.effective_metric_}')
print(f'샘플수: {neigh.n_samples_fit_}')
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
print(neigh.score(x_test,y_test))
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
new_x = [1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
new_df = pd.DataFrame([new_x], columns=x_train.columns)
prediction = neigh.predict(new_df)
prediction
```

```{python}
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn import datasets
diabetes = datasets.load_diabetes()
x = diabetes.data[:150]
y = diabetes.target[:150]
knn=KNeighborsClassifier()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
scores=cross_val_score(knn,x,y,cv=3,scoring='accuracy')
for i in range(scores.size):
    print(f"{i+1}번째 정확도: {scores[i]}")
```

<br>

## 9.3. (실습) 농구선수 분류

<br>

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 206}
df = pd.read_csv('./data/chap11_basketball_final.csv')
df.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
df.info()
```

```{python}
df['Target'].value_counts()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 425}
# 경력별 선수의 수
plt.figure(figsize=(5, 3))
sns.countplot(x=df['Target']) 
plt.title("Player")
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 경력에 따른 농구 기술
print(f"리바운드\n {df['Rebounds'].groupby(df['Target']).mean()}")
print(f"어시스트\n {df['Assists'].groupby(df['Target']).mean()}")
print(f"스틸\n {df['Steals'].groupby(df['Target']).mean()}")
print(f"블록\n {df['Blocks'].groupby(df['Target']).mean()}")
print(f"턴오버\n {df['Turnovers'].groupby(df['Target']).mean()}")
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 훈련데이터와 테스트데이터 분리
x=df[['Rebounds','Assists','Steals','Blocks','Turnovers']]
y=df[['Target']]
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2)
print(x_train.shape)
print(x_test.shape)
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 최적의 k찾기
from sklearn.model_selection import cross_val_score
knn=KNeighborsClassifier()
scores=cross_val_score(knn,x,y,cv=5, scoring='accuracy')

for i in range(scores.size):
    print(f"{i+1}번째 정확도: {scores[i]}")
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# 모델 생성과 학습
from sklearn.neighbors import KNeighborsClassifier
neigh=KNeighborsClassifier(n_neighbors=7)
neigh.fit(x_train, y_train)
print(neigh.classes_)
print(f'거리계산방법: {neigh.effective_metric_}')
print(f'샘플수: {neigh.n_samples_fit_}')
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
print(neigh.score(x_test,y_test))
new_x = [3,3,2,2,4]
prediction = neigh.predict([new_x])
print(prediction)
```

